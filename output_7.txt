reached here to decoder
模型加载成功: 使用第5个epoch的检查点

输入问题: what is love?
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 1])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 1
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 1])
  Token embedding: torch.Size([1, 1, 512])
  Position embedding: torch.Size([1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 1])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 1
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 1])
  Token embedding: torch.Size([1, 1, 512])
  Position embedding: torch.Size([1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 1, 512])
--------------------------------------------------
  v: torch.Size([1, 1, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 1])
score dimension torch.Size([1, 8, 1, 1])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 1, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 1, 13])
score dimension torch.Size([1, 8, 1, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 1, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 1, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 2])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 2
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 2])
  Token embedding: torch.Size([1, 2, 512])
  Position embedding: torch.Size([2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 2, 512])
--------------------------------------------------
  v: torch.Size([1, 2, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 2])
score dimension torch.Size([1, 8, 2, 2])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 13])
score dimension torch.Size([1, 8, 2, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 2, 512])
--------------------------------------------------
  v: torch.Size([1, 2, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 2])
score dimension torch.Size([1, 8, 2, 2])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 13])
score dimension torch.Size([1, 8, 2, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 2, 512])
--------------------------------------------------
  v: torch.Size([1, 2, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 2])
score dimension torch.Size([1, 8, 2, 2])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 13])
score dimension torch.Size([1, 8, 2, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 2, 512])
--------------------------------------------------
  v: torch.Size([1, 2, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 2])
score dimension torch.Size([1, 8, 2, 2])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 13])
score dimension torch.Size([1, 8, 2, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 2, 512])
--------------------------------------------------
  v: torch.Size([1, 2, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 2])
score dimension torch.Size([1, 8, 2, 2])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 13])
score dimension torch.Size([1, 8, 2, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 2, 512])
--------------------------------------------------
  v: torch.Size([1, 2, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 2])
score dimension torch.Size([1, 8, 2, 2])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 2, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 2, 13])
score dimension torch.Size([1, 8, 2, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 2, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 2, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 3])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 3
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 3])
  Token embedding: torch.Size([1, 3, 512])
  Position embedding: torch.Size([3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 3, 512])
--------------------------------------------------
  v: torch.Size([1, 3, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 3])
score dimension torch.Size([1, 8, 3, 3])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 13])
score dimension torch.Size([1, 8, 3, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 3, 512])
--------------------------------------------------
  v: torch.Size([1, 3, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 3])
score dimension torch.Size([1, 8, 3, 3])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 13])
score dimension torch.Size([1, 8, 3, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 3, 512])
--------------------------------------------------
  v: torch.Size([1, 3, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 3])
score dimension torch.Size([1, 8, 3, 3])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 13])
score dimension torch.Size([1, 8, 3, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 3, 512])
--------------------------------------------------
  v: torch.Size([1, 3, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 3])
score dimension torch.Size([1, 8, 3, 3])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 13])
score dimension torch.Size([1, 8, 3, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 3, 512])
--------------------------------------------------
  v: torch.Size([1, 3, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 3])
score dimension torch.Size([1, 8, 3, 3])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 13])
score dimension torch.Size([1, 8, 3, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 3, 512])
--------------------------------------------------
  v: torch.Size([1, 3, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 3])
score dimension torch.Size([1, 8, 3, 3])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 3, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 3, 13])
score dimension torch.Size([1, 8, 3, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 3, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 3, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 4])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 4
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 4])
  Token embedding: torch.Size([1, 4, 512])
  Position embedding: torch.Size([4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 4, 512])
--------------------------------------------------
  v: torch.Size([1, 4, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 4])
score dimension torch.Size([1, 8, 4, 4])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 13])
score dimension torch.Size([1, 8, 4, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 4, 512])
--------------------------------------------------
  v: torch.Size([1, 4, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 4])
score dimension torch.Size([1, 8, 4, 4])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 13])
score dimension torch.Size([1, 8, 4, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 4, 512])
--------------------------------------------------
  v: torch.Size([1, 4, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 4])
score dimension torch.Size([1, 8, 4, 4])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 13])
score dimension torch.Size([1, 8, 4, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 4, 512])
--------------------------------------------------
  v: torch.Size([1, 4, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 4])
score dimension torch.Size([1, 8, 4, 4])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 13])
score dimension torch.Size([1, 8, 4, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 4, 512])
--------------------------------------------------
  v: torch.Size([1, 4, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 4])
score dimension torch.Size([1, 8, 4, 4])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 13])
score dimension torch.Size([1, 8, 4, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 4, 512])
--------------------------------------------------
  v: torch.Size([1, 4, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 4])
score dimension torch.Size([1, 8, 4, 4])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 4, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 4, 13])
score dimension torch.Size([1, 8, 4, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 4, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 4, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 5])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 5
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 5])
  Token embedding: torch.Size([1, 5, 512])
  Position embedding: torch.Size([5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 5, 512])
--------------------------------------------------
  v: torch.Size([1, 5, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 5])
score dimension torch.Size([1, 8, 5, 5])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 13])
score dimension torch.Size([1, 8, 5, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 5, 512])
--------------------------------------------------
  v: torch.Size([1, 5, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 5])
score dimension torch.Size([1, 8, 5, 5])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 13])
score dimension torch.Size([1, 8, 5, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 5, 512])
--------------------------------------------------
  v: torch.Size([1, 5, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 5])
score dimension torch.Size([1, 8, 5, 5])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 13])
score dimension torch.Size([1, 8, 5, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 5, 512])
--------------------------------------------------
  v: torch.Size([1, 5, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 5])
score dimension torch.Size([1, 8, 5, 5])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 13])
score dimension torch.Size([1, 8, 5, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 5, 512])
--------------------------------------------------
  v: torch.Size([1, 5, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 5])
score dimension torch.Size([1, 8, 5, 5])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 13])
score dimension torch.Size([1, 8, 5, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 5, 512])
--------------------------------------------------
  v: torch.Size([1, 5, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 5])
score dimension torch.Size([1, 8, 5, 5])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 5, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 5, 13])
score dimension torch.Size([1, 8, 5, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 5, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 5, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 6])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 6
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 6])
  Token embedding: torch.Size([1, 6, 512])
  Position embedding: torch.Size([6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 6, 512])
--------------------------------------------------
  v: torch.Size([1, 6, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 6])
score dimension torch.Size([1, 8, 6, 6])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 13])
score dimension torch.Size([1, 8, 6, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 6, 512])
--------------------------------------------------
  v: torch.Size([1, 6, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 6])
score dimension torch.Size([1, 8, 6, 6])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 13])
score dimension torch.Size([1, 8, 6, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 6, 512])
--------------------------------------------------
  v: torch.Size([1, 6, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 6])
score dimension torch.Size([1, 8, 6, 6])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 13])
score dimension torch.Size([1, 8, 6, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 6, 512])
--------------------------------------------------
  v: torch.Size([1, 6, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 6])
score dimension torch.Size([1, 8, 6, 6])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 13])
score dimension torch.Size([1, 8, 6, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 6, 512])
--------------------------------------------------
  v: torch.Size([1, 6, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 6])
score dimension torch.Size([1, 8, 6, 6])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 13])
score dimension torch.Size([1, 8, 6, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 6, 512])
--------------------------------------------------
  v: torch.Size([1, 6, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 6])
score dimension torch.Size([1, 8, 6, 6])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 6, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 6, 13])
score dimension torch.Size([1, 8, 6, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 6, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 6, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 7])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 7
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 7])
  Token embedding: torch.Size([1, 7, 512])
  Position embedding: torch.Size([7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 7, 512])
--------------------------------------------------
  v: torch.Size([1, 7, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 7])
score dimension torch.Size([1, 8, 7, 7])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 13])
score dimension torch.Size([1, 8, 7, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 7, 512])
--------------------------------------------------
  v: torch.Size([1, 7, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 7])
score dimension torch.Size([1, 8, 7, 7])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 13])
score dimension torch.Size([1, 8, 7, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 7, 512])
--------------------------------------------------
  v: torch.Size([1, 7, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 7])
score dimension torch.Size([1, 8, 7, 7])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 13])
score dimension torch.Size([1, 8, 7, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 7, 512])
--------------------------------------------------
  v: torch.Size([1, 7, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 7])
score dimension torch.Size([1, 8, 7, 7])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 13])
score dimension torch.Size([1, 8, 7, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 7, 512])
--------------------------------------------------
  v: torch.Size([1, 7, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 7])
score dimension torch.Size([1, 8, 7, 7])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 13])
score dimension torch.Size([1, 8, 7, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 7, 512])
--------------------------------------------------
  v: torch.Size([1, 7, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 7])
score dimension torch.Size([1, 8, 7, 7])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 7, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 7, 13])
score dimension torch.Size([1, 8, 7, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 7, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 7, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 8])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 8
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 8])
  Token embedding: torch.Size([1, 8, 512])
  Position embedding: torch.Size([8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 8, 512])
--------------------------------------------------
  v: torch.Size([1, 8, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 8])
score dimension torch.Size([1, 8, 8, 8])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 13])
score dimension torch.Size([1, 8, 8, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 8, 512])
--------------------------------------------------
  v: torch.Size([1, 8, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 8])
score dimension torch.Size([1, 8, 8, 8])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 13])
score dimension torch.Size([1, 8, 8, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 8, 512])
--------------------------------------------------
  v: torch.Size([1, 8, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 8])
score dimension torch.Size([1, 8, 8, 8])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 13])
score dimension torch.Size([1, 8, 8, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 8, 512])
--------------------------------------------------
  v: torch.Size([1, 8, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 8])
score dimension torch.Size([1, 8, 8, 8])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 13])
score dimension torch.Size([1, 8, 8, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 8, 512])
--------------------------------------------------
  v: torch.Size([1, 8, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 8])
score dimension torch.Size([1, 8, 8, 8])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 13])
score dimension torch.Size([1, 8, 8, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 8, 512])
--------------------------------------------------
  v: torch.Size([1, 8, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 8])
score dimension torch.Size([1, 8, 8, 8])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 8, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 8, 13])
score dimension torch.Size([1, 8, 8, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 8, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 8, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 9])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 9
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 9])
  Token embedding: torch.Size([1, 9, 512])
  Position embedding: torch.Size([9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 9, 512])
--------------------------------------------------
  v: torch.Size([1, 9, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 9])
score dimension torch.Size([1, 8, 9, 9])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 13])
score dimension torch.Size([1, 8, 9, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 9, 512])
--------------------------------------------------
  v: torch.Size([1, 9, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 9])
score dimension torch.Size([1, 8, 9, 9])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 13])
score dimension torch.Size([1, 8, 9, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 9, 512])
--------------------------------------------------
  v: torch.Size([1, 9, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 9])
score dimension torch.Size([1, 8, 9, 9])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 13])
score dimension torch.Size([1, 8, 9, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 9, 512])
--------------------------------------------------
  v: torch.Size([1, 9, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 9])
score dimension torch.Size([1, 8, 9, 9])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 13])
score dimension torch.Size([1, 8, 9, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 9, 512])
--------------------------------------------------
  v: torch.Size([1, 9, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 9])
score dimension torch.Size([1, 8, 9, 9])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 13])
score dimension torch.Size([1, 8, 9, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 9, 512])
--------------------------------------------------
  v: torch.Size([1, 9, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 9])
score dimension torch.Size([1, 8, 9, 9])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 9, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 9, 13])
score dimension torch.Size([1, 8, 9, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 9, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 9, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 10])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 10
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 10])
  Token embedding: torch.Size([1, 10, 512])
  Position embedding: torch.Size([10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 10, 512])
--------------------------------------------------
  v: torch.Size([1, 10, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 10])
score dimension torch.Size([1, 8, 10, 10])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 13])
score dimension torch.Size([1, 8, 10, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 10, 512])
--------------------------------------------------
  v: torch.Size([1, 10, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 10])
score dimension torch.Size([1, 8, 10, 10])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 13])
score dimension torch.Size([1, 8, 10, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 10, 512])
--------------------------------------------------
  v: torch.Size([1, 10, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 10])
score dimension torch.Size([1, 8, 10, 10])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 13])
score dimension torch.Size([1, 8, 10, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 10, 512])
--------------------------------------------------
  v: torch.Size([1, 10, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 10])
score dimension torch.Size([1, 8, 10, 10])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 13])
score dimension torch.Size([1, 8, 10, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 10, 512])
--------------------------------------------------
  v: torch.Size([1, 10, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 10])
score dimension torch.Size([1, 8, 10, 10])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 13])
score dimension torch.Size([1, 8, 10, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 10, 512])
--------------------------------------------------
  v: torch.Size([1, 10, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 10])
score dimension torch.Size([1, 8, 10, 10])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 10, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 10, 13])
score dimension torch.Size([1, 8, 10, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 10, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 10, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 11])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 11
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 11])
  Token embedding: torch.Size([1, 11, 512])
  Position embedding: torch.Size([11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 11, 512])
--------------------------------------------------
  v: torch.Size([1, 11, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 11])
score dimension torch.Size([1, 8, 11, 11])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 13])
score dimension torch.Size([1, 8, 11, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 11, 512])
--------------------------------------------------
  v: torch.Size([1, 11, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 11])
score dimension torch.Size([1, 8, 11, 11])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 13])
score dimension torch.Size([1, 8, 11, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 11, 512])
--------------------------------------------------
  v: torch.Size([1, 11, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 11])
score dimension torch.Size([1, 8, 11, 11])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 13])
score dimension torch.Size([1, 8, 11, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 11, 512])
--------------------------------------------------
  v: torch.Size([1, 11, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 11])
score dimension torch.Size([1, 8, 11, 11])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 13])
score dimension torch.Size([1, 8, 11, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 11, 512])
--------------------------------------------------
  v: torch.Size([1, 11, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 11])
score dimension torch.Size([1, 8, 11, 11])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 13])
score dimension torch.Size([1, 8, 11, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 11, 512])
--------------------------------------------------
  v: torch.Size([1, 11, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 11])
score dimension torch.Size([1, 8, 11, 11])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 11, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 11, 13])
score dimension torch.Size([1, 8, 11, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 11, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 11, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 12])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 12
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 12])
  Token embedding: torch.Size([1, 12, 512])
  Position embedding: torch.Size([12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 12, 512])
--------------------------------------------------
  v: torch.Size([1, 12, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 12])
score dimension torch.Size([1, 8, 12, 12])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 13])
score dimension torch.Size([1, 8, 12, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 12, 512])
--------------------------------------------------
  v: torch.Size([1, 12, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 12])
score dimension torch.Size([1, 8, 12, 12])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 13])
score dimension torch.Size([1, 8, 12, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 12, 512])
--------------------------------------------------
  v: torch.Size([1, 12, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 12])
score dimension torch.Size([1, 8, 12, 12])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 13])
score dimension torch.Size([1, 8, 12, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 12, 512])
--------------------------------------------------
  v: torch.Size([1, 12, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 12])
score dimension torch.Size([1, 8, 12, 12])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 13])
score dimension torch.Size([1, 8, 12, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 12, 512])
--------------------------------------------------
  v: torch.Size([1, 12, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 12])
score dimension torch.Size([1, 8, 12, 12])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 13])
score dimension torch.Size([1, 8, 12, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 12, 512])
--------------------------------------------------
  v: torch.Size([1, 12, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 12])
score dimension torch.Size([1, 8, 12, 12])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 12, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 12, 13])
score dimension torch.Size([1, 8, 12, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 12, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 12, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 14])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 14
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 14])
  Token embedding: torch.Size([1, 14, 512])
  Position embedding: torch.Size([14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 14, 512])
--------------------------------------------------
  v: torch.Size([1, 14, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 14])
score dimension torch.Size([1, 8, 14, 14])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 13])
score dimension torch.Size([1, 8, 14, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 14, 512])
--------------------------------------------------
  v: torch.Size([1, 14, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 14])
score dimension torch.Size([1, 8, 14, 14])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 13])
score dimension torch.Size([1, 8, 14, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 14, 512])
--------------------------------------------------
  v: torch.Size([1, 14, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 14])
score dimension torch.Size([1, 8, 14, 14])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 13])
score dimension torch.Size([1, 8, 14, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 14, 512])
--------------------------------------------------
  v: torch.Size([1, 14, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 14])
score dimension torch.Size([1, 8, 14, 14])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 13])
score dimension torch.Size([1, 8, 14, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 14, 512])
--------------------------------------------------
  v: torch.Size([1, 14, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 14])
score dimension torch.Size([1, 8, 14, 14])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 13])
score dimension torch.Size([1, 8, 14, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 14, 512])
--------------------------------------------------
  v: torch.Size([1, 14, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 14])
score dimension torch.Size([1, 8, 14, 14])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 14, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 14, 13])
score dimension torch.Size([1, 8, 14, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 14, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 14, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 15])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 15
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 15])
  Token embedding: torch.Size([1, 15, 512])
  Position embedding: torch.Size([15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 15, 512])
--------------------------------------------------
  v: torch.Size([1, 15, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 15])
score dimension torch.Size([1, 8, 15, 15])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 13])
score dimension torch.Size([1, 8, 15, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 15, 512])
--------------------------------------------------
  v: torch.Size([1, 15, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 15])
score dimension torch.Size([1, 8, 15, 15])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 13])
score dimension torch.Size([1, 8, 15, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 15, 512])
--------------------------------------------------
  v: torch.Size([1, 15, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 15])
score dimension torch.Size([1, 8, 15, 15])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 13])
score dimension torch.Size([1, 8, 15, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 15, 512])
--------------------------------------------------
  v: torch.Size([1, 15, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 15])
score dimension torch.Size([1, 8, 15, 15])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 13])
score dimension torch.Size([1, 8, 15, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 15, 512])
--------------------------------------------------
  v: torch.Size([1, 15, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 15])
score dimension torch.Size([1, 8, 15, 15])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 13])
score dimension torch.Size([1, 8, 15, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 15, 512])
--------------------------------------------------
  v: torch.Size([1, 15, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 15])
score dimension torch.Size([1, 8, 15, 15])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 15, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 15, 13])
score dimension torch.Size([1, 8, 15, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 15, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 15, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 16])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 16
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 16])
  Token embedding: torch.Size([1, 16, 512])
  Position embedding: torch.Size([16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 16, 512])
--------------------------------------------------
  v: torch.Size([1, 16, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 16])
score dimension torch.Size([1, 8, 16, 16])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 13])
score dimension torch.Size([1, 8, 16, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 16, 512])
--------------------------------------------------
  v: torch.Size([1, 16, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 16])
score dimension torch.Size([1, 8, 16, 16])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 13])
score dimension torch.Size([1, 8, 16, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 16, 512])
--------------------------------------------------
  v: torch.Size([1, 16, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 16])
score dimension torch.Size([1, 8, 16, 16])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 13])
score dimension torch.Size([1, 8, 16, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 16, 512])
--------------------------------------------------
  v: torch.Size([1, 16, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 16])
score dimension torch.Size([1, 8, 16, 16])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 13])
score dimension torch.Size([1, 8, 16, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 16, 512])
--------------------------------------------------
  v: torch.Size([1, 16, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 16])
score dimension torch.Size([1, 8, 16, 16])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 13])
score dimension torch.Size([1, 8, 16, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 16, 512])
--------------------------------------------------
  v: torch.Size([1, 16, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 16])
score dimension torch.Size([1, 8, 16, 16])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 16, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 16, 13])
score dimension torch.Size([1, 8, 16, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 16, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 16, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 17])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 17
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 17])
  Token embedding: torch.Size([1, 17, 512])
  Position embedding: torch.Size([17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 17, 512])
--------------------------------------------------
  v: torch.Size([1, 17, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 17])
score dimension torch.Size([1, 8, 17, 17])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 13])
score dimension torch.Size([1, 8, 17, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 17, 512])
--------------------------------------------------
  v: torch.Size([1, 17, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 17])
score dimension torch.Size([1, 8, 17, 17])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 13])
score dimension torch.Size([1, 8, 17, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 17, 512])
--------------------------------------------------
  v: torch.Size([1, 17, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 17])
score dimension torch.Size([1, 8, 17, 17])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 13])
score dimension torch.Size([1, 8, 17, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 17, 512])
--------------------------------------------------
  v: torch.Size([1, 17, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 17])
score dimension torch.Size([1, 8, 17, 17])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 13])
score dimension torch.Size([1, 8, 17, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 17, 512])
--------------------------------------------------
  v: torch.Size([1, 17, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 17])
score dimension torch.Size([1, 8, 17, 17])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 13])
score dimension torch.Size([1, 8, 17, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 17, 512])
--------------------------------------------------
  v: torch.Size([1, 17, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 17])
score dimension torch.Size([1, 8, 17, 17])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 17, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 17, 13])
score dimension torch.Size([1, 8, 17, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 17, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 17, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 18])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 18
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 18])
  Token embedding: torch.Size([1, 18, 512])
  Position embedding: torch.Size([18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 18, 512])
--------------------------------------------------
  v: torch.Size([1, 18, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 18])
score dimension torch.Size([1, 8, 18, 18])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 13])
score dimension torch.Size([1, 8, 18, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 18, 512])
--------------------------------------------------
  v: torch.Size([1, 18, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 18])
score dimension torch.Size([1, 8, 18, 18])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 13])
score dimension torch.Size([1, 8, 18, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 18, 512])
--------------------------------------------------
  v: torch.Size([1, 18, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 18])
score dimension torch.Size([1, 8, 18, 18])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 13])
score dimension torch.Size([1, 8, 18, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 18, 512])
--------------------------------------------------
  v: torch.Size([1, 18, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 18])
score dimension torch.Size([1, 8, 18, 18])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 13])
score dimension torch.Size([1, 8, 18, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 18, 512])
--------------------------------------------------
  v: torch.Size([1, 18, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 18])
score dimension torch.Size([1, 8, 18, 18])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 13])
score dimension torch.Size([1, 8, 18, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 18, 512])
--------------------------------------------------
  v: torch.Size([1, 18, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 18])
score dimension torch.Size([1, 8, 18, 18])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 18, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 18, 13])
score dimension torch.Size([1, 8, 18, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 18, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 18, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 19])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 19
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 19])
  Token embedding: torch.Size([1, 19, 512])
  Position embedding: torch.Size([19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 19, 512])
--------------------------------------------------
  v: torch.Size([1, 19, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 19])
score dimension torch.Size([1, 8, 19, 19])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 13])
score dimension torch.Size([1, 8, 19, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 19, 512])
--------------------------------------------------
  v: torch.Size([1, 19, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 19])
score dimension torch.Size([1, 8, 19, 19])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 13])
score dimension torch.Size([1, 8, 19, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 19, 512])
--------------------------------------------------
  v: torch.Size([1, 19, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 19])
score dimension torch.Size([1, 8, 19, 19])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 13])
score dimension torch.Size([1, 8, 19, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 19, 512])
--------------------------------------------------
  v: torch.Size([1, 19, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 19])
score dimension torch.Size([1, 8, 19, 19])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 13])
score dimension torch.Size([1, 8, 19, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 19, 512])
--------------------------------------------------
  v: torch.Size([1, 19, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 19])
score dimension torch.Size([1, 8, 19, 19])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 13])
score dimension torch.Size([1, 8, 19, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 19, 512])
--------------------------------------------------
  v: torch.Size([1, 19, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 19])
score dimension torch.Size([1, 8, 19, 19])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 19, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 19, 13])
score dimension torch.Size([1, 8, 19, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 19, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 19, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 20])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 20
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 20])
  Token embedding: torch.Size([1, 20, 512])
  Position embedding: torch.Size([20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 20, 512])
--------------------------------------------------
  v: torch.Size([1, 20, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 20])
score dimension torch.Size([1, 8, 20, 20])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 13])
score dimension torch.Size([1, 8, 20, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 20, 512])
--------------------------------------------------
  v: torch.Size([1, 20, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 20])
score dimension torch.Size([1, 8, 20, 20])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 13])
score dimension torch.Size([1, 8, 20, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 20, 512])
--------------------------------------------------
  v: torch.Size([1, 20, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 20])
score dimension torch.Size([1, 8, 20, 20])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 13])
score dimension torch.Size([1, 8, 20, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 20, 512])
--------------------------------------------------
  v: torch.Size([1, 20, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 20])
score dimension torch.Size([1, 8, 20, 20])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 13])
score dimension torch.Size([1, 8, 20, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 20, 512])
--------------------------------------------------
  v: torch.Size([1, 20, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 20])
score dimension torch.Size([1, 8, 20, 20])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 13])
score dimension torch.Size([1, 8, 20, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 20, 512])
--------------------------------------------------
  v: torch.Size([1, 20, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 20])
score dimension torch.Size([1, 8, 20, 20])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 20, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 20, 13])
score dimension torch.Size([1, 8, 20, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 20, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 20, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 21])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 21
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 21])
  Token embedding: torch.Size([1, 21, 512])
  Position embedding: torch.Size([21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 21, 512])
--------------------------------------------------
  v: torch.Size([1, 21, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 21])
score dimension torch.Size([1, 8, 21, 21])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 13])
score dimension torch.Size([1, 8, 21, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 21, 512])
--------------------------------------------------
  v: torch.Size([1, 21, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 21])
score dimension torch.Size([1, 8, 21, 21])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 13])
score dimension torch.Size([1, 8, 21, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 21, 512])
--------------------------------------------------
  v: torch.Size([1, 21, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 21])
score dimension torch.Size([1, 8, 21, 21])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 13])
score dimension torch.Size([1, 8, 21, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 21, 512])
--------------------------------------------------
  v: torch.Size([1, 21, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 21])
score dimension torch.Size([1, 8, 21, 21])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 13])
score dimension torch.Size([1, 8, 21, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 21, 512])
--------------------------------------------------
  v: torch.Size([1, 21, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 21])
score dimension torch.Size([1, 8, 21, 21])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 13])
score dimension torch.Size([1, 8, 21, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 21, 512])
--------------------------------------------------
  v: torch.Size([1, 21, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 21])
score dimension torch.Size([1, 8, 21, 21])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 21, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 21, 13])
score dimension torch.Size([1, 8, 21, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 21, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 21, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 22])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 22
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 22])
  Token embedding: torch.Size([1, 22, 512])
  Position embedding: torch.Size([22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 22, 512])
--------------------------------------------------
  v: torch.Size([1, 22, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 22])
score dimension torch.Size([1, 8, 22, 22])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 13])
score dimension torch.Size([1, 8, 22, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 22, 512])
--------------------------------------------------
  v: torch.Size([1, 22, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 22])
score dimension torch.Size([1, 8, 22, 22])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 13])
score dimension torch.Size([1, 8, 22, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 22, 512])
--------------------------------------------------
  v: torch.Size([1, 22, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 22])
score dimension torch.Size([1, 8, 22, 22])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 13])
score dimension torch.Size([1, 8, 22, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 22, 512])
--------------------------------------------------
  v: torch.Size([1, 22, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 22])
score dimension torch.Size([1, 8, 22, 22])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 13])
score dimension torch.Size([1, 8, 22, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 22, 512])
--------------------------------------------------
  v: torch.Size([1, 22, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 22])
score dimension torch.Size([1, 8, 22, 22])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 13])
score dimension torch.Size([1, 8, 22, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 22, 512])
--------------------------------------------------
  v: torch.Size([1, 22, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 22])
score dimension torch.Size([1, 8, 22, 22])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 22, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 22, 13])
score dimension torch.Size([1, 8, 22, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 22, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 22, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 23])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 23
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 23])
  Token embedding: torch.Size([1, 23, 512])
  Position embedding: torch.Size([23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 23, 512])
--------------------------------------------------
  v: torch.Size([1, 23, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 23])
score dimension torch.Size([1, 8, 23, 23])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 13])
score dimension torch.Size([1, 8, 23, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 23, 512])
--------------------------------------------------
  v: torch.Size([1, 23, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 23])
score dimension torch.Size([1, 8, 23, 23])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 13])
score dimension torch.Size([1, 8, 23, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 23, 512])
--------------------------------------------------
  v: torch.Size([1, 23, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 23])
score dimension torch.Size([1, 8, 23, 23])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 13])
score dimension torch.Size([1, 8, 23, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 23, 512])
--------------------------------------------------
  v: torch.Size([1, 23, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 23])
score dimension torch.Size([1, 8, 23, 23])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 13])
score dimension torch.Size([1, 8, 23, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 23, 512])
--------------------------------------------------
  v: torch.Size([1, 23, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 23])
score dimension torch.Size([1, 8, 23, 23])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 13])
score dimension torch.Size([1, 8, 23, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 23, 512])
--------------------------------------------------
  v: torch.Size([1, 23, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 23])
score dimension torch.Size([1, 8, 23, 23])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 23, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 23, 13])
score dimension torch.Size([1, 8, 23, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 23, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 23, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 24])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 24
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 24])
  Token embedding: torch.Size([1, 24, 512])
  Position embedding: torch.Size([24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 24, 512])
--------------------------------------------------
  v: torch.Size([1, 24, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 24])
score dimension torch.Size([1, 8, 24, 24])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 13])
score dimension torch.Size([1, 8, 24, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 24, 512])
--------------------------------------------------
  v: torch.Size([1, 24, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 24])
score dimension torch.Size([1, 8, 24, 24])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 13])
score dimension torch.Size([1, 8, 24, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 24, 512])
--------------------------------------------------
  v: torch.Size([1, 24, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 24])
score dimension torch.Size([1, 8, 24, 24])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 13])
score dimension torch.Size([1, 8, 24, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 24, 512])
--------------------------------------------------
  v: torch.Size([1, 24, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 24])
score dimension torch.Size([1, 8, 24, 24])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 13])
score dimension torch.Size([1, 8, 24, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 24, 512])
--------------------------------------------------
  v: torch.Size([1, 24, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 24])
score dimension torch.Size([1, 8, 24, 24])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 13])
score dimension torch.Size([1, 8, 24, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 24, 512])
--------------------------------------------------
  v: torch.Size([1, 24, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 24])
score dimension torch.Size([1, 8, 24, 24])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 24, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 24, 13])
score dimension torch.Size([1, 8, 24, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 24, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 24, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 25])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 25
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 25])
  Token embedding: torch.Size([1, 25, 512])
  Position embedding: torch.Size([25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 25, 512])
--------------------------------------------------
  v: torch.Size([1, 25, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 25])
score dimension torch.Size([1, 8, 25, 25])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 13])
score dimension torch.Size([1, 8, 25, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 25, 512])
--------------------------------------------------
  v: torch.Size([1, 25, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 25])
score dimension torch.Size([1, 8, 25, 25])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 13])
score dimension torch.Size([1, 8, 25, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 25, 512])
--------------------------------------------------
  v: torch.Size([1, 25, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 25])
score dimension torch.Size([1, 8, 25, 25])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 13])
score dimension torch.Size([1, 8, 25, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 25, 512])
--------------------------------------------------
  v: torch.Size([1, 25, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 25])
score dimension torch.Size([1, 8, 25, 25])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 13])
score dimension torch.Size([1, 8, 25, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 25, 512])
--------------------------------------------------
  v: torch.Size([1, 25, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 25])
score dimension torch.Size([1, 8, 25, 25])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 13])
score dimension torch.Size([1, 8, 25, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 25, 512])
--------------------------------------------------
  v: torch.Size([1, 25, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 25])
score dimension torch.Size([1, 8, 25, 25])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 25, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 25, 13])
score dimension torch.Size([1, 8, 25, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 25, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 25, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 26])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 26
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 26])
  Token embedding: torch.Size([1, 26, 512])
  Position embedding: torch.Size([26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 26, 512])
--------------------------------------------------
  v: torch.Size([1, 26, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 26])
score dimension torch.Size([1, 8, 26, 26])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 13])
score dimension torch.Size([1, 8, 26, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 26, 512])
--------------------------------------------------
  v: torch.Size([1, 26, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 26])
score dimension torch.Size([1, 8, 26, 26])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 13])
score dimension torch.Size([1, 8, 26, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 26, 512])
--------------------------------------------------
  v: torch.Size([1, 26, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 26])
score dimension torch.Size([1, 8, 26, 26])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 13])
score dimension torch.Size([1, 8, 26, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 26, 512])
--------------------------------------------------
  v: torch.Size([1, 26, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 26])
score dimension torch.Size([1, 8, 26, 26])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 13])
score dimension torch.Size([1, 8, 26, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 26, 512])
--------------------------------------------------
  v: torch.Size([1, 26, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 26])
score dimension torch.Size([1, 8, 26, 26])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 13])
score dimension torch.Size([1, 8, 26, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 26, 512])
--------------------------------------------------
  v: torch.Size([1, 26, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 26])
score dimension torch.Size([1, 8, 26, 26])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 26, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 26, 13])
score dimension torch.Size([1, 8, 26, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 26, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 26, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 27])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 27
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 27])
  Token embedding: torch.Size([1, 27, 512])
  Position embedding: torch.Size([27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 27, 512])
--------------------------------------------------
  v: torch.Size([1, 27, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 27])
score dimension torch.Size([1, 8, 27, 27])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 13])
score dimension torch.Size([1, 8, 27, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 27, 512])
--------------------------------------------------
  v: torch.Size([1, 27, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 27])
score dimension torch.Size([1, 8, 27, 27])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 13])
score dimension torch.Size([1, 8, 27, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 27, 512])
--------------------------------------------------
  v: torch.Size([1, 27, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 27])
score dimension torch.Size([1, 8, 27, 27])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 13])
score dimension torch.Size([1, 8, 27, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 27, 512])
--------------------------------------------------
  v: torch.Size([1, 27, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 27])
score dimension torch.Size([1, 8, 27, 27])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 13])
score dimension torch.Size([1, 8, 27, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 27, 512])
--------------------------------------------------
  v: torch.Size([1, 27, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 27])
score dimension torch.Size([1, 8, 27, 27])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 13])
score dimension torch.Size([1, 8, 27, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 27, 512])
--------------------------------------------------
  v: torch.Size([1, 27, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 27])
score dimension torch.Size([1, 8, 27, 27])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 27, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 27, 13])
score dimension torch.Size([1, 8, 27, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 27, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 27, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 28])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 28
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 28])
  Token embedding: torch.Size([1, 28, 512])
  Position embedding: torch.Size([28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 28, 512])
--------------------------------------------------
  v: torch.Size([1, 28, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 28])
score dimension torch.Size([1, 8, 28, 28])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 13])
score dimension torch.Size([1, 8, 28, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 28, 512])
--------------------------------------------------
  v: torch.Size([1, 28, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 28])
score dimension torch.Size([1, 8, 28, 28])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 13])
score dimension torch.Size([1, 8, 28, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 28, 512])
--------------------------------------------------
  v: torch.Size([1, 28, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 28])
score dimension torch.Size([1, 8, 28, 28])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 13])
score dimension torch.Size([1, 8, 28, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 28, 512])
--------------------------------------------------
  v: torch.Size([1, 28, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 28])
score dimension torch.Size([1, 8, 28, 28])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 13])
score dimension torch.Size([1, 8, 28, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 28, 512])
--------------------------------------------------
  v: torch.Size([1, 28, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 28])
score dimension torch.Size([1, 8, 28, 28])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 13])
score dimension torch.Size([1, 8, 28, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 28, 512])
--------------------------------------------------
  v: torch.Size([1, 28, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 28])
score dimension torch.Size([1, 8, 28, 28])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 28, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 28, 13])
score dimension torch.Size([1, 8, 28, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 28, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 28, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 29])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 29
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 29])
  Token embedding: torch.Size([1, 29, 512])
  Position embedding: torch.Size([29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 29, 512])
--------------------------------------------------
  v: torch.Size([1, 29, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 29])
score dimension torch.Size([1, 8, 29, 29])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 13])
score dimension torch.Size([1, 8, 29, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 29, 512])
--------------------------------------------------
  v: torch.Size([1, 29, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 29])
score dimension torch.Size([1, 8, 29, 29])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 13])
score dimension torch.Size([1, 8, 29, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 29, 512])
--------------------------------------------------
  v: torch.Size([1, 29, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 29])
score dimension torch.Size([1, 8, 29, 29])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 13])
score dimension torch.Size([1, 8, 29, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 29, 512])
--------------------------------------------------
  v: torch.Size([1, 29, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 29])
score dimension torch.Size([1, 8, 29, 29])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 13])
score dimension torch.Size([1, 8, 29, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 29, 512])
--------------------------------------------------
  v: torch.Size([1, 29, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 29])
score dimension torch.Size([1, 8, 29, 29])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 13])
score dimension torch.Size([1, 8, 29, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 29, 512])
--------------------------------------------------
  v: torch.Size([1, 29, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 29])
score dimension torch.Size([1, 8, 29, 29])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 29, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 29, 13])
score dimension torch.Size([1, 8, 29, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 29, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 29, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 30])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 30
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 30])
  Token embedding: torch.Size([1, 30, 512])
  Position embedding: torch.Size([30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 30, 512])
--------------------------------------------------
  v: torch.Size([1, 30, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 30])
score dimension torch.Size([1, 8, 30, 30])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 13])
score dimension torch.Size([1, 8, 30, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 30, 512])
--------------------------------------------------
  v: torch.Size([1, 30, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 30])
score dimension torch.Size([1, 8, 30, 30])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 13])
score dimension torch.Size([1, 8, 30, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 30, 512])
--------------------------------------------------
  v: torch.Size([1, 30, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 30])
score dimension torch.Size([1, 8, 30, 30])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 13])
score dimension torch.Size([1, 8, 30, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 30, 512])
--------------------------------------------------
  v: torch.Size([1, 30, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 30])
score dimension torch.Size([1, 8, 30, 30])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 13])
score dimension torch.Size([1, 8, 30, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 30, 512])
--------------------------------------------------
  v: torch.Size([1, 30, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 30])
score dimension torch.Size([1, 8, 30, 30])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 13])
score dimension torch.Size([1, 8, 30, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 30, 512])
--------------------------------------------------
  v: torch.Size([1, 30, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 30])
score dimension torch.Size([1, 8, 30, 30])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 30, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 30, 13])
score dimension torch.Size([1, 8, 30, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 30, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 30, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 31])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 31
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 31])
  Token embedding: torch.Size([1, 31, 512])
  Position embedding: torch.Size([31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 31, 512])
--------------------------------------------------
  v: torch.Size([1, 31, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 31])
score dimension torch.Size([1, 8, 31, 31])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 13])
score dimension torch.Size([1, 8, 31, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 31, 512])
--------------------------------------------------
  v: torch.Size([1, 31, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 31])
score dimension torch.Size([1, 8, 31, 31])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 13])
score dimension torch.Size([1, 8, 31, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 31, 512])
--------------------------------------------------
  v: torch.Size([1, 31, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 31])
score dimension torch.Size([1, 8, 31, 31])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 13])
score dimension torch.Size([1, 8, 31, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 31, 512])
--------------------------------------------------
  v: torch.Size([1, 31, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 31])
score dimension torch.Size([1, 8, 31, 31])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 13])
score dimension torch.Size([1, 8, 31, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 31, 512])
--------------------------------------------------
  v: torch.Size([1, 31, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 31])
score dimension torch.Size([1, 8, 31, 31])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 13])
score dimension torch.Size([1, 8, 31, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 31, 512])
--------------------------------------------------
  v: torch.Size([1, 31, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 31])
score dimension torch.Size([1, 8, 31, 31])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 31, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 31, 13])
score dimension torch.Size([1, 8, 31, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 31, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 31, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 32])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 32
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 32])
  Token embedding: torch.Size([1, 32, 512])
  Position embedding: torch.Size([32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 32, 512])
--------------------------------------------------
  v: torch.Size([1, 32, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 32])
score dimension torch.Size([1, 8, 32, 32])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 13])
score dimension torch.Size([1, 8, 32, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 32, 512])
--------------------------------------------------
  v: torch.Size([1, 32, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 32])
score dimension torch.Size([1, 8, 32, 32])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 13])
score dimension torch.Size([1, 8, 32, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 32, 512])
--------------------------------------------------
  v: torch.Size([1, 32, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 32])
score dimension torch.Size([1, 8, 32, 32])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 13])
score dimension torch.Size([1, 8, 32, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 32, 512])
--------------------------------------------------
  v: torch.Size([1, 32, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 32])
score dimension torch.Size([1, 8, 32, 32])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 13])
score dimension torch.Size([1, 8, 32, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 32, 512])
--------------------------------------------------
  v: torch.Size([1, 32, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 32])
score dimension torch.Size([1, 8, 32, 32])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 13])
score dimension torch.Size([1, 8, 32, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 32, 512])
--------------------------------------------------
  v: torch.Size([1, 32, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 32])
score dimension torch.Size([1, 8, 32, 32])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 32, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 32, 13])
score dimension torch.Size([1, 8, 32, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 32, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 32, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 33])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 33
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 33])
  Token embedding: torch.Size([1, 33, 512])
  Position embedding: torch.Size([33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 33, 512])
--------------------------------------------------
  v: torch.Size([1, 33, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 33])
score dimension torch.Size([1, 8, 33, 33])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 13])
score dimension torch.Size([1, 8, 33, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 33, 512])
--------------------------------------------------
  v: torch.Size([1, 33, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 33])
score dimension torch.Size([1, 8, 33, 33])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 13])
score dimension torch.Size([1, 8, 33, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 33, 512])
--------------------------------------------------
  v: torch.Size([1, 33, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 33])
score dimension torch.Size([1, 8, 33, 33])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 13])
score dimension torch.Size([1, 8, 33, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 33, 512])
--------------------------------------------------
  v: torch.Size([1, 33, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 33])
score dimension torch.Size([1, 8, 33, 33])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 13])
score dimension torch.Size([1, 8, 33, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 33, 512])
--------------------------------------------------
  v: torch.Size([1, 33, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 33])
score dimension torch.Size([1, 8, 33, 33])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 13])
score dimension torch.Size([1, 8, 33, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 33, 512])
--------------------------------------------------
  v: torch.Size([1, 33, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 33])
score dimension torch.Size([1, 8, 33, 33])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 33, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 33, 13])
score dimension torch.Size([1, 8, 33, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 33, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 33, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 34])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 34
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 34])
  Token embedding: torch.Size([1, 34, 512])
  Position embedding: torch.Size([34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 34, 512])
--------------------------------------------------
  v: torch.Size([1, 34, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 34])
score dimension torch.Size([1, 8, 34, 34])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 13])
score dimension torch.Size([1, 8, 34, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 34, 512])
--------------------------------------------------
  v: torch.Size([1, 34, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 34])
score dimension torch.Size([1, 8, 34, 34])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 13])
score dimension torch.Size([1, 8, 34, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 34, 512])
--------------------------------------------------
  v: torch.Size([1, 34, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 34])
score dimension torch.Size([1, 8, 34, 34])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 13])
score dimension torch.Size([1, 8, 34, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 34, 512])
--------------------------------------------------
  v: torch.Size([1, 34, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 34])
score dimension torch.Size([1, 8, 34, 34])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 13])
score dimension torch.Size([1, 8, 34, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 34, 512])
--------------------------------------------------
  v: torch.Size([1, 34, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 34])
score dimension torch.Size([1, 8, 34, 34])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 13])
score dimension torch.Size([1, 8, 34, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 34, 512])
--------------------------------------------------
  v: torch.Size([1, 34, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 34])
score dimension torch.Size([1, 8, 34, 34])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 34, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 34, 13])
score dimension torch.Size([1, 8, 34, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 34, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 34, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 35])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 35
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 35])
  Token embedding: torch.Size([1, 35, 512])
  Position embedding: torch.Size([35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 35, 512])
--------------------------------------------------
  v: torch.Size([1, 35, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 35])
score dimension torch.Size([1, 8, 35, 35])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 13])
score dimension torch.Size([1, 8, 35, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 35, 512])
--------------------------------------------------
  v: torch.Size([1, 35, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 35])
score dimension torch.Size([1, 8, 35, 35])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 13])
score dimension torch.Size([1, 8, 35, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 35, 512])
--------------------------------------------------
  v: torch.Size([1, 35, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 35])
score dimension torch.Size([1, 8, 35, 35])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 13])
score dimension torch.Size([1, 8, 35, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 35, 512])
--------------------------------------------------
  v: torch.Size([1, 35, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 35])
score dimension torch.Size([1, 8, 35, 35])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 13])
score dimension torch.Size([1, 8, 35, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 35, 512])
--------------------------------------------------
  v: torch.Size([1, 35, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 35])
score dimension torch.Size([1, 8, 35, 35])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 13])
score dimension torch.Size([1, 8, 35, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 35, 512])
--------------------------------------------------
  v: torch.Size([1, 35, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 35])
score dimension torch.Size([1, 8, 35, 35])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 35, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 35, 13])
score dimension torch.Size([1, 8, 35, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 35, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 35, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 36])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 36
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 36])
  Token embedding: torch.Size([1, 36, 512])
  Position embedding: torch.Size([36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 36, 512])
--------------------------------------------------
  v: torch.Size([1, 36, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 36])
score dimension torch.Size([1, 8, 36, 36])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 13])
score dimension torch.Size([1, 8, 36, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 36, 512])
--------------------------------------------------
  v: torch.Size([1, 36, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 36])
score dimension torch.Size([1, 8, 36, 36])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 13])
score dimension torch.Size([1, 8, 36, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 36, 512])
--------------------------------------------------
  v: torch.Size([1, 36, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 36])
score dimension torch.Size([1, 8, 36, 36])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 13])
score dimension torch.Size([1, 8, 36, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 36, 512])
--------------------------------------------------
  v: torch.Size([1, 36, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 36])
score dimension torch.Size([1, 8, 36, 36])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 13])
score dimension torch.Size([1, 8, 36, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 36, 512])
--------------------------------------------------
  v: torch.Size([1, 36, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 36])
score dimension torch.Size([1, 8, 36, 36])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 13])
score dimension torch.Size([1, 8, 36, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 36, 512])
--------------------------------------------------
  v: torch.Size([1, 36, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 36])
score dimension torch.Size([1, 8, 36, 36])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 36, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 36, 13])
score dimension torch.Size([1, 8, 36, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 36, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 36, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 37])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 37
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 37])
  Token embedding: torch.Size([1, 37, 512])
  Position embedding: torch.Size([37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 37, 512])
--------------------------------------------------
  v: torch.Size([1, 37, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 37])
score dimension torch.Size([1, 8, 37, 37])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 13])
score dimension torch.Size([1, 8, 37, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 37, 512])
--------------------------------------------------
  v: torch.Size([1, 37, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 37])
score dimension torch.Size([1, 8, 37, 37])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 13])
score dimension torch.Size([1, 8, 37, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 37, 512])
--------------------------------------------------
  v: torch.Size([1, 37, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 37])
score dimension torch.Size([1, 8, 37, 37])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 13])
score dimension torch.Size([1, 8, 37, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 37, 512])
--------------------------------------------------
  v: torch.Size([1, 37, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 37])
score dimension torch.Size([1, 8, 37, 37])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 13])
score dimension torch.Size([1, 8, 37, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 37, 512])
--------------------------------------------------
  v: torch.Size([1, 37, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 37])
score dimension torch.Size([1, 8, 37, 37])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 13])
score dimension torch.Size([1, 8, 37, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 37, 512])
--------------------------------------------------
  v: torch.Size([1, 37, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 37])
score dimension torch.Size([1, 8, 37, 37])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 37, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 37, 13])
score dimension torch.Size([1, 8, 37, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 37, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 37, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 38])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 38
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 38])
  Token embedding: torch.Size([1, 38, 512])
  Position embedding: torch.Size([38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 38, 512])
--------------------------------------------------
  v: torch.Size([1, 38, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 38])
score dimension torch.Size([1, 8, 38, 38])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 13])
score dimension torch.Size([1, 8, 38, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 38, 512])
--------------------------------------------------
  v: torch.Size([1, 38, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 38])
score dimension torch.Size([1, 8, 38, 38])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 13])
score dimension torch.Size([1, 8, 38, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 38, 512])
--------------------------------------------------
  v: torch.Size([1, 38, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 38])
score dimension torch.Size([1, 8, 38, 38])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 13])
score dimension torch.Size([1, 8, 38, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 38, 512])
--------------------------------------------------
  v: torch.Size([1, 38, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 38])
score dimension torch.Size([1, 8, 38, 38])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 13])
score dimension torch.Size([1, 8, 38, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 38, 512])
--------------------------------------------------
  v: torch.Size([1, 38, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 38])
score dimension torch.Size([1, 8, 38, 38])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 13])
score dimension torch.Size([1, 8, 38, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 38, 512])
--------------------------------------------------
  v: torch.Size([1, 38, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 38])
score dimension torch.Size([1, 8, 38, 38])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 38, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 38, 13])
score dimension torch.Size([1, 8, 38, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 38, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 38, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 39])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 39
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 39])
  Token embedding: torch.Size([1, 39, 512])
  Position embedding: torch.Size([39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 39, 512])
--------------------------------------------------
  v: torch.Size([1, 39, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 39])
score dimension torch.Size([1, 8, 39, 39])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 13])
score dimension torch.Size([1, 8, 39, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 39, 512])
--------------------------------------------------
  v: torch.Size([1, 39, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 39])
score dimension torch.Size([1, 8, 39, 39])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 13])
score dimension torch.Size([1, 8, 39, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 39, 512])
--------------------------------------------------
  v: torch.Size([1, 39, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 39])
score dimension torch.Size([1, 8, 39, 39])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 13])
score dimension torch.Size([1, 8, 39, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 39, 512])
--------------------------------------------------
  v: torch.Size([1, 39, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 39])
score dimension torch.Size([1, 8, 39, 39])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 13])
score dimension torch.Size([1, 8, 39, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 39, 512])
--------------------------------------------------
  v: torch.Size([1, 39, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 39])
score dimension torch.Size([1, 8, 39, 39])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 13])
score dimension torch.Size([1, 8, 39, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 39, 512])
--------------------------------------------------
  v: torch.Size([1, 39, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 39])
score dimension torch.Size([1, 8, 39, 39])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 39, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 39, 13])
score dimension torch.Size([1, 8, 39, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 39, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 39, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 40])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 40
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 40])
  Token embedding: torch.Size([1, 40, 512])
  Position embedding: torch.Size([40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 40, 512])
--------------------------------------------------
  v: torch.Size([1, 40, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 40])
score dimension torch.Size([1, 8, 40, 40])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 13])
score dimension torch.Size([1, 8, 40, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 40, 512])
--------------------------------------------------
  v: torch.Size([1, 40, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 40])
score dimension torch.Size([1, 8, 40, 40])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 13])
score dimension torch.Size([1, 8, 40, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 40, 512])
--------------------------------------------------
  v: torch.Size([1, 40, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 40])
score dimension torch.Size([1, 8, 40, 40])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 13])
score dimension torch.Size([1, 8, 40, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 40, 512])
--------------------------------------------------
  v: torch.Size([1, 40, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 40])
score dimension torch.Size([1, 8, 40, 40])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 13])
score dimension torch.Size([1, 8, 40, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 40, 512])
--------------------------------------------------
  v: torch.Size([1, 40, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 40])
score dimension torch.Size([1, 8, 40, 40])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 13])
score dimension torch.Size([1, 8, 40, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 40, 512])
--------------------------------------------------
  v: torch.Size([1, 40, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 40])
score dimension torch.Size([1, 8, 40, 40])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 40, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 40, 13])
score dimension torch.Size([1, 8, 40, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 40, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 40, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 41])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 41
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 41])
  Token embedding: torch.Size([1, 41, 512])
  Position embedding: torch.Size([41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 41, 512])
--------------------------------------------------
  v: torch.Size([1, 41, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 41])
score dimension torch.Size([1, 8, 41, 41])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 13])
score dimension torch.Size([1, 8, 41, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 41, 512])
--------------------------------------------------
  v: torch.Size([1, 41, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 41])
score dimension torch.Size([1, 8, 41, 41])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 13])
score dimension torch.Size([1, 8, 41, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 41, 512])
--------------------------------------------------
  v: torch.Size([1, 41, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 41])
score dimension torch.Size([1, 8, 41, 41])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 13])
score dimension torch.Size([1, 8, 41, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 41, 512])
--------------------------------------------------
  v: torch.Size([1, 41, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 41])
score dimension torch.Size([1, 8, 41, 41])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 13])
score dimension torch.Size([1, 8, 41, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 41, 512])
--------------------------------------------------
  v: torch.Size([1, 41, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 41])
score dimension torch.Size([1, 8, 41, 41])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 13])
score dimension torch.Size([1, 8, 41, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 41, 512])
--------------------------------------------------
  v: torch.Size([1, 41, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 41])
score dimension torch.Size([1, 8, 41, 41])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 41, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 41, 13])
score dimension torch.Size([1, 8, 41, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 41, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 41, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 42])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 42
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 42])
  Token embedding: torch.Size([1, 42, 512])
  Position embedding: torch.Size([42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 42, 512])
--------------------------------------------------
  v: torch.Size([1, 42, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 42])
score dimension torch.Size([1, 8, 42, 42])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 13])
score dimension torch.Size([1, 8, 42, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 42, 512])
--------------------------------------------------
  v: torch.Size([1, 42, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 42])
score dimension torch.Size([1, 8, 42, 42])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 13])
score dimension torch.Size([1, 8, 42, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 42, 512])
--------------------------------------------------
  v: torch.Size([1, 42, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 42])
score dimension torch.Size([1, 8, 42, 42])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 13])
score dimension torch.Size([1, 8, 42, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 42, 512])
--------------------------------------------------
  v: torch.Size([1, 42, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 42])
score dimension torch.Size([1, 8, 42, 42])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 13])
score dimension torch.Size([1, 8, 42, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 42, 512])
--------------------------------------------------
  v: torch.Size([1, 42, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 42])
score dimension torch.Size([1, 8, 42, 42])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 13])
score dimension torch.Size([1, 8, 42, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 42, 512])
--------------------------------------------------
  v: torch.Size([1, 42, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 42])
score dimension torch.Size([1, 8, 42, 42])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 42, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 42, 13])
score dimension torch.Size([1, 8, 42, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 42, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 42, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 43])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 43
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 43])
  Token embedding: torch.Size([1, 43, 512])
  Position embedding: torch.Size([43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 43, 512])
--------------------------------------------------
  v: torch.Size([1, 43, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 43])
score dimension torch.Size([1, 8, 43, 43])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 13])
score dimension torch.Size([1, 8, 43, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 43, 512])
--------------------------------------------------
  v: torch.Size([1, 43, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 43])
score dimension torch.Size([1, 8, 43, 43])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 13])
score dimension torch.Size([1, 8, 43, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 43, 512])
--------------------------------------------------
  v: torch.Size([1, 43, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 43])
score dimension torch.Size([1, 8, 43, 43])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 13])
score dimension torch.Size([1, 8, 43, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 43, 512])
--------------------------------------------------
  v: torch.Size([1, 43, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 43])
score dimension torch.Size([1, 8, 43, 43])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 13])
score dimension torch.Size([1, 8, 43, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 43, 512])
--------------------------------------------------
  v: torch.Size([1, 43, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 43])
score dimension torch.Size([1, 8, 43, 43])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 13])
score dimension torch.Size([1, 8, 43, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 43, 512])
--------------------------------------------------
  v: torch.Size([1, 43, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 43])
score dimension torch.Size([1, 8, 43, 43])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 43, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 43, 13])
score dimension torch.Size([1, 8, 43, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 43, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 43, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 44])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 44
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 44])
  Token embedding: torch.Size([1, 44, 512])
  Position embedding: torch.Size([44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 44, 512])
--------------------------------------------------
  v: torch.Size([1, 44, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 44])
score dimension torch.Size([1, 8, 44, 44])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 13])
score dimension torch.Size([1, 8, 44, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 44, 512])
--------------------------------------------------
  v: torch.Size([1, 44, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 44])
score dimension torch.Size([1, 8, 44, 44])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 13])
score dimension torch.Size([1, 8, 44, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 44, 512])
--------------------------------------------------
  v: torch.Size([1, 44, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 44])
score dimension torch.Size([1, 8, 44, 44])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 13])
score dimension torch.Size([1, 8, 44, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 44, 512])
--------------------------------------------------
  v: torch.Size([1, 44, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 44])
score dimension torch.Size([1, 8, 44, 44])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 13])
score dimension torch.Size([1, 8, 44, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 44, 512])
--------------------------------------------------
  v: torch.Size([1, 44, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 44])
score dimension torch.Size([1, 8, 44, 44])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 13])
score dimension torch.Size([1, 8, 44, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 44, 512])
--------------------------------------------------
  v: torch.Size([1, 44, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 44])
score dimension torch.Size([1, 8, 44, 44])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 44, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 44, 13])
score dimension torch.Size([1, 8, 44, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 44, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 44, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 45])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 45
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 45])
  Token embedding: torch.Size([1, 45, 512])
  Position embedding: torch.Size([45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 45, 512])
--------------------------------------------------
  v: torch.Size([1, 45, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 45])
score dimension torch.Size([1, 8, 45, 45])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 13])
score dimension torch.Size([1, 8, 45, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 45, 512])
--------------------------------------------------
  v: torch.Size([1, 45, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 45])
score dimension torch.Size([1, 8, 45, 45])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 13])
score dimension torch.Size([1, 8, 45, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 45, 512])
--------------------------------------------------
  v: torch.Size([1, 45, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 45])
score dimension torch.Size([1, 8, 45, 45])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 13])
score dimension torch.Size([1, 8, 45, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 45, 512])
--------------------------------------------------
  v: torch.Size([1, 45, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 45])
score dimension torch.Size([1, 8, 45, 45])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 13])
score dimension torch.Size([1, 8, 45, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 45, 512])
--------------------------------------------------
  v: torch.Size([1, 45, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 45])
score dimension torch.Size([1, 8, 45, 45])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 13])
score dimension torch.Size([1, 8, 45, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 45, 512])
--------------------------------------------------
  v: torch.Size([1, 45, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 45])
score dimension torch.Size([1, 8, 45, 45])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 45, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 45, 13])
score dimension torch.Size([1, 8, 45, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 45, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 45, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 46])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 46
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 46])
  Token embedding: torch.Size([1, 46, 512])
  Position embedding: torch.Size([46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 46, 512])
--------------------------------------------------
  v: torch.Size([1, 46, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 46])
score dimension torch.Size([1, 8, 46, 46])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 13])
score dimension torch.Size([1, 8, 46, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 46, 512])
--------------------------------------------------
  v: torch.Size([1, 46, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 46])
score dimension torch.Size([1, 8, 46, 46])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 13])
score dimension torch.Size([1, 8, 46, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 46, 512])
--------------------------------------------------
  v: torch.Size([1, 46, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 46])
score dimension torch.Size([1, 8, 46, 46])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 13])
score dimension torch.Size([1, 8, 46, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 46, 512])
--------------------------------------------------
  v: torch.Size([1, 46, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 46])
score dimension torch.Size([1, 8, 46, 46])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 13])
score dimension torch.Size([1, 8, 46, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 46, 512])
--------------------------------------------------
  v: torch.Size([1, 46, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 46])
score dimension torch.Size([1, 8, 46, 46])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 13])
score dimension torch.Size([1, 8, 46, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 46, 512])
--------------------------------------------------
  v: torch.Size([1, 46, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 46])
score dimension torch.Size([1, 8, 46, 46])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 46, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 46, 13])
score dimension torch.Size([1, 8, 46, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 46, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 46, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 47])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 47
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 47])
  Token embedding: torch.Size([1, 47, 512])
  Position embedding: torch.Size([47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 47, 512])
--------------------------------------------------
  v: torch.Size([1, 47, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 47])
score dimension torch.Size([1, 8, 47, 47])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 13])
score dimension torch.Size([1, 8, 47, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 47, 512])
--------------------------------------------------
  v: torch.Size([1, 47, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 47])
score dimension torch.Size([1, 8, 47, 47])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 13])
score dimension torch.Size([1, 8, 47, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 47, 512])
--------------------------------------------------
  v: torch.Size([1, 47, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 47])
score dimension torch.Size([1, 8, 47, 47])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 13])
score dimension torch.Size([1, 8, 47, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 47, 512])
--------------------------------------------------
  v: torch.Size([1, 47, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 47])
score dimension torch.Size([1, 8, 47, 47])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 13])
score dimension torch.Size([1, 8, 47, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 47, 512])
--------------------------------------------------
  v: torch.Size([1, 47, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 47])
score dimension torch.Size([1, 8, 47, 47])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 13])
score dimension torch.Size([1, 8, 47, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 47, 512])
--------------------------------------------------
  v: torch.Size([1, 47, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 47])
score dimension torch.Size([1, 8, 47, 47])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 47, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 47, 13])
score dimension torch.Size([1, 8, 47, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 47, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 47, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 48])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 48
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 48])
  Token embedding: torch.Size([1, 48, 512])
  Position embedding: torch.Size([48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 48, 512])
--------------------------------------------------
  v: torch.Size([1, 48, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 48])
score dimension torch.Size([1, 8, 48, 48])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 13])
score dimension torch.Size([1, 8, 48, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 48, 512])
--------------------------------------------------
  v: torch.Size([1, 48, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 48])
score dimension torch.Size([1, 8, 48, 48])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 13])
score dimension torch.Size([1, 8, 48, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 48, 512])
--------------------------------------------------
  v: torch.Size([1, 48, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 48])
score dimension torch.Size([1, 8, 48, 48])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 13])
score dimension torch.Size([1, 8, 48, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 48, 512])
--------------------------------------------------
  v: torch.Size([1, 48, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 48])
score dimension torch.Size([1, 8, 48, 48])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 13])
score dimension torch.Size([1, 8, 48, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 48, 512])
--------------------------------------------------
  v: torch.Size([1, 48, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 48])
score dimension torch.Size([1, 8, 48, 48])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 13])
score dimension torch.Size([1, 8, 48, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 48, 512])
--------------------------------------------------
  v: torch.Size([1, 48, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 48])
score dimension torch.Size([1, 8, 48, 48])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 48, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 48, 13])
score dimension torch.Size([1, 8, 48, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 48, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 48, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 49])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 49
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 49])
  Token embedding: torch.Size([1, 49, 512])
  Position embedding: torch.Size([49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 49, 512])
--------------------------------------------------
  v: torch.Size([1, 49, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 49])
score dimension torch.Size([1, 8, 49, 49])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 13])
score dimension torch.Size([1, 8, 49, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 49, 512])
--------------------------------------------------
  v: torch.Size([1, 49, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 49])
score dimension torch.Size([1, 8, 49, 49])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 13])
score dimension torch.Size([1, 8, 49, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 49, 512])
--------------------------------------------------
  v: torch.Size([1, 49, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 49])
score dimension torch.Size([1, 8, 49, 49])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 13])
score dimension torch.Size([1, 8, 49, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 49, 512])
--------------------------------------------------
  v: torch.Size([1, 49, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 49])
score dimension torch.Size([1, 8, 49, 49])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 13])
score dimension torch.Size([1, 8, 49, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 49, 512])
--------------------------------------------------
  v: torch.Size([1, 49, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 49])
score dimension torch.Size([1, 8, 49, 49])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 13])
score dimension torch.Size([1, 8, 49, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 49, 512])
--------------------------------------------------
  v: torch.Size([1, 49, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 49])
score dimension torch.Size([1, 8, 49, 49])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 49, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 49, 13])
score dimension torch.Size([1, 8, 49, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 49, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 49, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 50])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 50
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 50])
  Token embedding: torch.Size([1, 50, 512])
  Position embedding: torch.Size([50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 50, 512])
--------------------------------------------------
  v: torch.Size([1, 50, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 50])
score dimension torch.Size([1, 8, 50, 50])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 13])
score dimension torch.Size([1, 8, 50, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 50, 512])
--------------------------------------------------
  v: torch.Size([1, 50, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 50])
score dimension torch.Size([1, 8, 50, 50])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 13])
score dimension torch.Size([1, 8, 50, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 50, 512])
--------------------------------------------------
  v: torch.Size([1, 50, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 50])
score dimension torch.Size([1, 8, 50, 50])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 13])
score dimension torch.Size([1, 8, 50, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 50, 512])
--------------------------------------------------
  v: torch.Size([1, 50, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 50])
score dimension torch.Size([1, 8, 50, 50])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 13])
score dimension torch.Size([1, 8, 50, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 50, 512])
--------------------------------------------------
  v: torch.Size([1, 50, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 50])
score dimension torch.Size([1, 8, 50, 50])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 13])
score dimension torch.Size([1, 8, 50, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 50, 512])
--------------------------------------------------
  v: torch.Size([1, 50, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 50])
score dimension torch.Size([1, 8, 50, 50])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 50, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 50, 13])
score dimension torch.Size([1, 8, 50, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 50, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 50, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 51])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 51
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 51])
  Token embedding: torch.Size([1, 51, 512])
  Position embedding: torch.Size([51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 51, 512])
--------------------------------------------------
  v: torch.Size([1, 51, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 51])
score dimension torch.Size([1, 8, 51, 51])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 13])
score dimension torch.Size([1, 8, 51, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 51, 512])
--------------------------------------------------
  v: torch.Size([1, 51, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 51])
score dimension torch.Size([1, 8, 51, 51])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 13])
score dimension torch.Size([1, 8, 51, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 51, 512])
--------------------------------------------------
  v: torch.Size([1, 51, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 51])
score dimension torch.Size([1, 8, 51, 51])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 13])
score dimension torch.Size([1, 8, 51, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 51, 512])
--------------------------------------------------
  v: torch.Size([1, 51, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 51])
score dimension torch.Size([1, 8, 51, 51])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 13])
score dimension torch.Size([1, 8, 51, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 51, 512])
--------------------------------------------------
  v: torch.Size([1, 51, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 51])
score dimension torch.Size([1, 8, 51, 51])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 13])
score dimension torch.Size([1, 8, 51, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 51, 512])
--------------------------------------------------
  v: torch.Size([1, 51, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 51])
score dimension torch.Size([1, 8, 51, 51])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 51, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 51, 13])
score dimension torch.Size([1, 8, 51, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 51, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 51, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 52])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 52
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 52])
  Token embedding: torch.Size([1, 52, 512])
  Position embedding: torch.Size([52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 52, 512])
--------------------------------------------------
  v: torch.Size([1, 52, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 52])
score dimension torch.Size([1, 8, 52, 52])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 13])
score dimension torch.Size([1, 8, 52, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 52, 512])
--------------------------------------------------
  v: torch.Size([1, 52, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 52])
score dimension torch.Size([1, 8, 52, 52])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 13])
score dimension torch.Size([1, 8, 52, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 52, 512])
--------------------------------------------------
  v: torch.Size([1, 52, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 52])
score dimension torch.Size([1, 8, 52, 52])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 13])
score dimension torch.Size([1, 8, 52, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 52, 512])
--------------------------------------------------
  v: torch.Size([1, 52, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 52])
score dimension torch.Size([1, 8, 52, 52])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 13])
score dimension torch.Size([1, 8, 52, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 52, 512])
--------------------------------------------------
  v: torch.Size([1, 52, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 52])
score dimension torch.Size([1, 8, 52, 52])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 13])
score dimension torch.Size([1, 8, 52, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 52, 512])
--------------------------------------------------
  v: torch.Size([1, 52, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 52])
score dimension torch.Size([1, 8, 52, 52])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 52, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 52, 13])
score dimension torch.Size([1, 8, 52, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 52, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 52, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 53])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 53
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 53])
  Token embedding: torch.Size([1, 53, 512])
  Position embedding: torch.Size([53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 53, 512])
--------------------------------------------------
  v: torch.Size([1, 53, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 53])
score dimension torch.Size([1, 8, 53, 53])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 13])
score dimension torch.Size([1, 8, 53, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 53, 512])
--------------------------------------------------
  v: torch.Size([1, 53, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 53])
score dimension torch.Size([1, 8, 53, 53])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 13])
score dimension torch.Size([1, 8, 53, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 53, 512])
--------------------------------------------------
  v: torch.Size([1, 53, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 53])
score dimension torch.Size([1, 8, 53, 53])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 13])
score dimension torch.Size([1, 8, 53, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 53, 512])
--------------------------------------------------
  v: torch.Size([1, 53, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 53])
score dimension torch.Size([1, 8, 53, 53])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 13])
score dimension torch.Size([1, 8, 53, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 53, 512])
--------------------------------------------------
  v: torch.Size([1, 53, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 53])
score dimension torch.Size([1, 8, 53, 53])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 13])
score dimension torch.Size([1, 8, 53, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 53, 512])
--------------------------------------------------
  v: torch.Size([1, 53, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 53])
score dimension torch.Size([1, 8, 53, 53])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 53, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 53, 13])
score dimension torch.Size([1, 8, 53, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 53, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 53, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 54])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 54
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 54])
  Token embedding: torch.Size([1, 54, 512])
  Position embedding: torch.Size([54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 54, 512])
--------------------------------------------------
  v: torch.Size([1, 54, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 54])
score dimension torch.Size([1, 8, 54, 54])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 13])
score dimension torch.Size([1, 8, 54, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 54, 512])
--------------------------------------------------
  v: torch.Size([1, 54, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 54])
score dimension torch.Size([1, 8, 54, 54])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 13])
score dimension torch.Size([1, 8, 54, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 54, 512])
--------------------------------------------------
  v: torch.Size([1, 54, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 54])
score dimension torch.Size([1, 8, 54, 54])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 13])
score dimension torch.Size([1, 8, 54, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 54, 512])
--------------------------------------------------
  v: torch.Size([1, 54, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 54])
score dimension torch.Size([1, 8, 54, 54])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 13])
score dimension torch.Size([1, 8, 54, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 54, 512])
--------------------------------------------------
  v: torch.Size([1, 54, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 54])
score dimension torch.Size([1, 8, 54, 54])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 13])
score dimension torch.Size([1, 8, 54, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 54, 512])
--------------------------------------------------
  v: torch.Size([1, 54, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 54])
score dimension torch.Size([1, 8, 54, 54])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 54, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 54, 13])
score dimension torch.Size([1, 8, 54, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 54, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 54, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 55])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 55
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 55])
  Token embedding: torch.Size([1, 55, 512])
  Position embedding: torch.Size([55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 55, 512])
--------------------------------------------------
  v: torch.Size([1, 55, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 55])
score dimension torch.Size([1, 8, 55, 55])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 13])
score dimension torch.Size([1, 8, 55, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 55, 512])
--------------------------------------------------
  v: torch.Size([1, 55, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 55])
score dimension torch.Size([1, 8, 55, 55])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 13])
score dimension torch.Size([1, 8, 55, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 55, 512])
--------------------------------------------------
  v: torch.Size([1, 55, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 55])
score dimension torch.Size([1, 8, 55, 55])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 13])
score dimension torch.Size([1, 8, 55, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 55, 512])
--------------------------------------------------
  v: torch.Size([1, 55, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 55])
score dimension torch.Size([1, 8, 55, 55])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 13])
score dimension torch.Size([1, 8, 55, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 55, 512])
--------------------------------------------------
  v: torch.Size([1, 55, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 55])
score dimension torch.Size([1, 8, 55, 55])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 13])
score dimension torch.Size([1, 8, 55, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 55, 512])
--------------------------------------------------
  v: torch.Size([1, 55, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 55])
score dimension torch.Size([1, 8, 55, 55])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 55, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 55, 13])
score dimension torch.Size([1, 8, 55, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 55, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 55, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 56])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 56
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 56])
  Token embedding: torch.Size([1, 56, 512])
  Position embedding: torch.Size([56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 56, 512])
--------------------------------------------------
  v: torch.Size([1, 56, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 56])
score dimension torch.Size([1, 8, 56, 56])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 13])
score dimension torch.Size([1, 8, 56, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 56, 512])
--------------------------------------------------
  v: torch.Size([1, 56, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 56])
score dimension torch.Size([1, 8, 56, 56])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 13])
score dimension torch.Size([1, 8, 56, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 56, 512])
--------------------------------------------------
  v: torch.Size([1, 56, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 56])
score dimension torch.Size([1, 8, 56, 56])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 13])
score dimension torch.Size([1, 8, 56, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 56, 512])
--------------------------------------------------
  v: torch.Size([1, 56, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 56])
score dimension torch.Size([1, 8, 56, 56])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 13])
score dimension torch.Size([1, 8, 56, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 56, 512])
--------------------------------------------------
  v: torch.Size([1, 56, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 56])
score dimension torch.Size([1, 8, 56, 56])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 13])
score dimension torch.Size([1, 8, 56, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 56, 512])
--------------------------------------------------
  v: torch.Size([1, 56, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 56])
score dimension torch.Size([1, 8, 56, 56])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 56, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 56, 13])
score dimension torch.Size([1, 8, 56, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 56, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 56, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 57])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 57
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 57])
  Token embedding: torch.Size([1, 57, 512])
  Position embedding: torch.Size([57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 57, 512])
--------------------------------------------------
  v: torch.Size([1, 57, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 57])
score dimension torch.Size([1, 8, 57, 57])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 13])
score dimension torch.Size([1, 8, 57, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 57, 512])
--------------------------------------------------
  v: torch.Size([1, 57, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 57])
score dimension torch.Size([1, 8, 57, 57])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 13])
score dimension torch.Size([1, 8, 57, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 57, 512])
--------------------------------------------------
  v: torch.Size([1, 57, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 57])
score dimension torch.Size([1, 8, 57, 57])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 13])
score dimension torch.Size([1, 8, 57, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 57, 512])
--------------------------------------------------
  v: torch.Size([1, 57, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 57])
score dimension torch.Size([1, 8, 57, 57])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 13])
score dimension torch.Size([1, 8, 57, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 57, 512])
--------------------------------------------------
  v: torch.Size([1, 57, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 57])
score dimension torch.Size([1, 8, 57, 57])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 13])
score dimension torch.Size([1, 8, 57, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 57, 512])
--------------------------------------------------
  v: torch.Size([1, 57, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 57])
score dimension torch.Size([1, 8, 57, 57])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 57, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 57, 13])
score dimension torch.Size([1, 8, 57, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 57, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 57, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 58])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 58
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 58])
  Token embedding: torch.Size([1, 58, 512])
  Position embedding: torch.Size([58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 58, 512])
--------------------------------------------------
  v: torch.Size([1, 58, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 58])
score dimension torch.Size([1, 8, 58, 58])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 13])
score dimension torch.Size([1, 8, 58, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 58, 512])
--------------------------------------------------
  v: torch.Size([1, 58, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 58])
score dimension torch.Size([1, 8, 58, 58])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 13])
score dimension torch.Size([1, 8, 58, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 58, 512])
--------------------------------------------------
  v: torch.Size([1, 58, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 58])
score dimension torch.Size([1, 8, 58, 58])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 13])
score dimension torch.Size([1, 8, 58, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 58, 512])
--------------------------------------------------
  v: torch.Size([1, 58, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 58])
score dimension torch.Size([1, 8, 58, 58])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 13])
score dimension torch.Size([1, 8, 58, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 58, 512])
--------------------------------------------------
  v: torch.Size([1, 58, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 58])
score dimension torch.Size([1, 8, 58, 58])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 13])
score dimension torch.Size([1, 8, 58, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 58, 512])
--------------------------------------------------
  v: torch.Size([1, 58, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 58])
score dimension torch.Size([1, 8, 58, 58])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 58, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 58, 13])
score dimension torch.Size([1, 8, 58, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 58, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 58, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 59])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 59
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 59])
  Token embedding: torch.Size([1, 59, 512])
  Position embedding: torch.Size([59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 59, 512])
--------------------------------------------------
  v: torch.Size([1, 59, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 59])
score dimension torch.Size([1, 8, 59, 59])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 13])
score dimension torch.Size([1, 8, 59, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 59, 512])
--------------------------------------------------
  v: torch.Size([1, 59, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 59])
score dimension torch.Size([1, 8, 59, 59])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 13])
score dimension torch.Size([1, 8, 59, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 59, 512])
--------------------------------------------------
  v: torch.Size([1, 59, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 59])
score dimension torch.Size([1, 8, 59, 59])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 13])
score dimension torch.Size([1, 8, 59, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 59, 512])
--------------------------------------------------
  v: torch.Size([1, 59, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 59])
score dimension torch.Size([1, 8, 59, 59])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 13])
score dimension torch.Size([1, 8, 59, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 59, 512])
--------------------------------------------------
  v: torch.Size([1, 59, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 59])
score dimension torch.Size([1, 8, 59, 59])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 13])
score dimension torch.Size([1, 8, 59, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 59, 512])
--------------------------------------------------
  v: torch.Size([1, 59, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 59])
score dimension torch.Size([1, 8, 59, 59])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 59, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 59, 13])
score dimension torch.Size([1, 8, 59, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 59, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 59, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 60])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 60
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 60])
  Token embedding: torch.Size([1, 60, 512])
  Position embedding: torch.Size([60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 60, 512])
--------------------------------------------------
  v: torch.Size([1, 60, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 60])
score dimension torch.Size([1, 8, 60, 60])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 13])
score dimension torch.Size([1, 8, 60, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 60, 512])
--------------------------------------------------
  v: torch.Size([1, 60, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 60])
score dimension torch.Size([1, 8, 60, 60])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 13])
score dimension torch.Size([1, 8, 60, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 60, 512])
--------------------------------------------------
  v: torch.Size([1, 60, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 60])
score dimension torch.Size([1, 8, 60, 60])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 13])
score dimension torch.Size([1, 8, 60, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 60, 512])
--------------------------------------------------
  v: torch.Size([1, 60, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 60])
score dimension torch.Size([1, 8, 60, 60])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 13])
score dimension torch.Size([1, 8, 60, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 60, 512])
--------------------------------------------------
  v: torch.Size([1, 60, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 60])
score dimension torch.Size([1, 8, 60, 60])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 13])
score dimension torch.Size([1, 8, 60, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 60, 512])
--------------------------------------------------
  v: torch.Size([1, 60, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 60])
score dimension torch.Size([1, 8, 60, 60])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 60, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 60, 13])
score dimension torch.Size([1, 8, 60, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 60, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 60, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 61])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 61
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 61])
  Token embedding: torch.Size([1, 61, 512])
  Position embedding: torch.Size([61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 61, 512])
--------------------------------------------------
  v: torch.Size([1, 61, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 61])
score dimension torch.Size([1, 8, 61, 61])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 13])
score dimension torch.Size([1, 8, 61, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 61, 512])
--------------------------------------------------
  v: torch.Size([1, 61, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 61])
score dimension torch.Size([1, 8, 61, 61])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 13])
score dimension torch.Size([1, 8, 61, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 61, 512])
--------------------------------------------------
  v: torch.Size([1, 61, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 61])
score dimension torch.Size([1, 8, 61, 61])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 13])
score dimension torch.Size([1, 8, 61, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 61, 512])
--------------------------------------------------
  v: torch.Size([1, 61, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 61])
score dimension torch.Size([1, 8, 61, 61])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 13])
score dimension torch.Size([1, 8, 61, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 61, 512])
--------------------------------------------------
  v: torch.Size([1, 61, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 61])
score dimension torch.Size([1, 8, 61, 61])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 13])
score dimension torch.Size([1, 8, 61, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 61, 512])
--------------------------------------------------
  v: torch.Size([1, 61, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 61])
score dimension torch.Size([1, 8, 61, 61])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 61, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 61, 13])
score dimension torch.Size([1, 8, 61, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 61, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 61, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 62])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 62
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 62])
  Token embedding: torch.Size([1, 62, 512])
  Position embedding: torch.Size([62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 62, 512])
--------------------------------------------------
  v: torch.Size([1, 62, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 62])
score dimension torch.Size([1, 8, 62, 62])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 13])
score dimension torch.Size([1, 8, 62, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 62, 512])
--------------------------------------------------
  v: torch.Size([1, 62, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 62])
score dimension torch.Size([1, 8, 62, 62])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 13])
score dimension torch.Size([1, 8, 62, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 62, 512])
--------------------------------------------------
  v: torch.Size([1, 62, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 62])
score dimension torch.Size([1, 8, 62, 62])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 13])
score dimension torch.Size([1, 8, 62, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 62, 512])
--------------------------------------------------
  v: torch.Size([1, 62, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 62])
score dimension torch.Size([1, 8, 62, 62])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 13])
score dimension torch.Size([1, 8, 62, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 62, 512])
--------------------------------------------------
  v: torch.Size([1, 62, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 62])
score dimension torch.Size([1, 8, 62, 62])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 13])
score dimension torch.Size([1, 8, 62, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 62, 512])
--------------------------------------------------
  v: torch.Size([1, 62, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 62])
score dimension torch.Size([1, 8, 62, 62])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 62, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 62, 13])
score dimension torch.Size([1, 8, 62, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 62, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 62, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 63])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 63
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 63])
  Token embedding: torch.Size([1, 63, 512])
  Position embedding: torch.Size([63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 63, 512])
--------------------------------------------------
  v: torch.Size([1, 63, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 63])
score dimension torch.Size([1, 8, 63, 63])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 13])
score dimension torch.Size([1, 8, 63, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 63, 512])
--------------------------------------------------
  v: torch.Size([1, 63, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 63])
score dimension torch.Size([1, 8, 63, 63])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 13])
score dimension torch.Size([1, 8, 63, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 63, 512])
--------------------------------------------------
  v: torch.Size([1, 63, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 63])
score dimension torch.Size([1, 8, 63, 63])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 13])
score dimension torch.Size([1, 8, 63, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 63, 512])
--------------------------------------------------
  v: torch.Size([1, 63, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 63])
score dimension torch.Size([1, 8, 63, 63])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 13])
score dimension torch.Size([1, 8, 63, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 63, 512])
--------------------------------------------------
  v: torch.Size([1, 63, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 63])
score dimension torch.Size([1, 8, 63, 63])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 13])
score dimension torch.Size([1, 8, 63, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 63, 512])
--------------------------------------------------
  v: torch.Size([1, 63, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 63])
score dimension torch.Size([1, 8, 63, 63])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 63, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 63, 13])
score dimension torch.Size([1, 8, 63, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 63, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 63, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 64])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 64
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 64])
  Token embedding: torch.Size([1, 64, 512])
  Position embedding: torch.Size([64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 64, 512])
--------------------------------------------------
  v: torch.Size([1, 64, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 64])
score dimension torch.Size([1, 8, 64, 64])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 13])
score dimension torch.Size([1, 8, 64, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 64, 512])
--------------------------------------------------
  v: torch.Size([1, 64, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 64])
score dimension torch.Size([1, 8, 64, 64])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 13])
score dimension torch.Size([1, 8, 64, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 64, 512])
--------------------------------------------------
  v: torch.Size([1, 64, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 64])
score dimension torch.Size([1, 8, 64, 64])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 13])
score dimension torch.Size([1, 8, 64, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 64, 512])
--------------------------------------------------
  v: torch.Size([1, 64, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 64])
score dimension torch.Size([1, 8, 64, 64])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 13])
score dimension torch.Size([1, 8, 64, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 64, 512])
--------------------------------------------------
  v: torch.Size([1, 64, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 64])
score dimension torch.Size([1, 8, 64, 64])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 13])
score dimension torch.Size([1, 8, 64, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 64, 512])
--------------------------------------------------
  v: torch.Size([1, 64, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 64])
score dimension torch.Size([1, 8, 64, 64])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 64, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 64, 13])
score dimension torch.Size([1, 8, 64, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 64, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 64, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 65])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 65
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 65])
  Token embedding: torch.Size([1, 65, 512])
  Position embedding: torch.Size([65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 65, 512])
--------------------------------------------------
  v: torch.Size([1, 65, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 65])
score dimension torch.Size([1, 8, 65, 65])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 13])
score dimension torch.Size([1, 8, 65, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 65, 512])
--------------------------------------------------
  v: torch.Size([1, 65, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 65])
score dimension torch.Size([1, 8, 65, 65])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 13])
score dimension torch.Size([1, 8, 65, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 65, 512])
--------------------------------------------------
  v: torch.Size([1, 65, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 65])
score dimension torch.Size([1, 8, 65, 65])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 13])
score dimension torch.Size([1, 8, 65, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 65, 512])
--------------------------------------------------
  v: torch.Size([1, 65, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 65])
score dimension torch.Size([1, 8, 65, 65])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 13])
score dimension torch.Size([1, 8, 65, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 65, 512])
--------------------------------------------------
  v: torch.Size([1, 65, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 65])
score dimension torch.Size([1, 8, 65, 65])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 13])
score dimension torch.Size([1, 8, 65, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 65, 512])
--------------------------------------------------
  v: torch.Size([1, 65, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 65])
score dimension torch.Size([1, 8, 65, 65])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 65, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 65, 13])
score dimension torch.Size([1, 8, 65, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 65, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 65, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 66])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 66
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 66])
  Token embedding: torch.Size([1, 66, 512])
  Position embedding: torch.Size([66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 66, 512])
--------------------------------------------------
  v: torch.Size([1, 66, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 66])
score dimension torch.Size([1, 8, 66, 66])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 13])
score dimension torch.Size([1, 8, 66, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 66, 512])
--------------------------------------------------
  v: torch.Size([1, 66, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 66])
score dimension torch.Size([1, 8, 66, 66])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 13])
score dimension torch.Size([1, 8, 66, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 66, 512])
--------------------------------------------------
  v: torch.Size([1, 66, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 66])
score dimension torch.Size([1, 8, 66, 66])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 13])
score dimension torch.Size([1, 8, 66, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 66, 512])
--------------------------------------------------
  v: torch.Size([1, 66, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 66])
score dimension torch.Size([1, 8, 66, 66])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 13])
score dimension torch.Size([1, 8, 66, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 66, 512])
--------------------------------------------------
  v: torch.Size([1, 66, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 66])
score dimension torch.Size([1, 8, 66, 66])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 13])
score dimension torch.Size([1, 8, 66, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 66, 512])
--------------------------------------------------
  v: torch.Size([1, 66, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 66])
score dimension torch.Size([1, 8, 66, 66])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 66, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 66, 13])
score dimension torch.Size([1, 8, 66, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 66, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 66, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 67])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 67
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 67])
  Token embedding: torch.Size([1, 67, 512])
  Position embedding: torch.Size([67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 67, 512])
--------------------------------------------------
  v: torch.Size([1, 67, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 67])
score dimension torch.Size([1, 8, 67, 67])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 13])
score dimension torch.Size([1, 8, 67, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 67, 512])
--------------------------------------------------
  v: torch.Size([1, 67, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 67])
score dimension torch.Size([1, 8, 67, 67])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 13])
score dimension torch.Size([1, 8, 67, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 67, 512])
--------------------------------------------------
  v: torch.Size([1, 67, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 67])
score dimension torch.Size([1, 8, 67, 67])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 13])
score dimension torch.Size([1, 8, 67, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 67, 512])
--------------------------------------------------
  v: torch.Size([1, 67, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 67])
score dimension torch.Size([1, 8, 67, 67])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 13])
score dimension torch.Size([1, 8, 67, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 67, 512])
--------------------------------------------------
  v: torch.Size([1, 67, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 67])
score dimension torch.Size([1, 8, 67, 67])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 13])
score dimension torch.Size([1, 8, 67, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 67, 512])
--------------------------------------------------
  v: torch.Size([1, 67, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 67])
score dimension torch.Size([1, 8, 67, 67])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 67, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 67, 13])
score dimension torch.Size([1, 8, 67, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 67, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 67, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 68])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 68
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 68])
  Token embedding: torch.Size([1, 68, 512])
  Position embedding: torch.Size([68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 68, 512])
--------------------------------------------------
  v: torch.Size([1, 68, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 68])
score dimension torch.Size([1, 8, 68, 68])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 13])
score dimension torch.Size([1, 8, 68, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 68, 512])
--------------------------------------------------
  v: torch.Size([1, 68, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 68])
score dimension torch.Size([1, 8, 68, 68])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 13])
score dimension torch.Size([1, 8, 68, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 68, 512])
--------------------------------------------------
  v: torch.Size([1, 68, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 68])
score dimension torch.Size([1, 8, 68, 68])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 13])
score dimension torch.Size([1, 8, 68, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 68, 512])
--------------------------------------------------
  v: torch.Size([1, 68, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 68])
score dimension torch.Size([1, 8, 68, 68])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 13])
score dimension torch.Size([1, 8, 68, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 68, 512])
--------------------------------------------------
  v: torch.Size([1, 68, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 68])
score dimension torch.Size([1, 8, 68, 68])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 13])
score dimension torch.Size([1, 8, 68, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 68, 512])
--------------------------------------------------
  v: torch.Size([1, 68, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 68])
score dimension torch.Size([1, 8, 68, 68])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 68, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 68, 13])
score dimension torch.Size([1, 8, 68, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 68, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 68, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 69])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 69
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 69])
  Token embedding: torch.Size([1, 69, 512])
  Position embedding: torch.Size([69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 69, 512])
--------------------------------------------------
  v: torch.Size([1, 69, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 69])
score dimension torch.Size([1, 8, 69, 69])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 13])
score dimension torch.Size([1, 8, 69, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 69, 512])
--------------------------------------------------
  v: torch.Size([1, 69, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 69])
score dimension torch.Size([1, 8, 69, 69])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 13])
score dimension torch.Size([1, 8, 69, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 69, 512])
--------------------------------------------------
  v: torch.Size([1, 69, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 69])
score dimension torch.Size([1, 8, 69, 69])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 13])
score dimension torch.Size([1, 8, 69, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 69, 512])
--------------------------------------------------
  v: torch.Size([1, 69, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 69])
score dimension torch.Size([1, 8, 69, 69])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 13])
score dimension torch.Size([1, 8, 69, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 69, 512])
--------------------------------------------------
  v: torch.Size([1, 69, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 69])
score dimension torch.Size([1, 8, 69, 69])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 13])
score dimension torch.Size([1, 8, 69, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 69, 512])
--------------------------------------------------
  v: torch.Size([1, 69, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 69])
score dimension torch.Size([1, 8, 69, 69])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 69, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 69, 13])
score dimension torch.Size([1, 8, 69, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 69, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 69, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 70])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 70
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 70])
  Token embedding: torch.Size([1, 70, 512])
  Position embedding: torch.Size([70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 70, 512])
--------------------------------------------------
  v: torch.Size([1, 70, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 70])
score dimension torch.Size([1, 8, 70, 70])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 13])
score dimension torch.Size([1, 8, 70, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 70, 512])
--------------------------------------------------
  v: torch.Size([1, 70, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 70])
score dimension torch.Size([1, 8, 70, 70])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 13])
score dimension torch.Size([1, 8, 70, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 70, 512])
--------------------------------------------------
  v: torch.Size([1, 70, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 70])
score dimension torch.Size([1, 8, 70, 70])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 13])
score dimension torch.Size([1, 8, 70, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 70, 512])
--------------------------------------------------
  v: torch.Size([1, 70, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 70])
score dimension torch.Size([1, 8, 70, 70])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 13])
score dimension torch.Size([1, 8, 70, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 70, 512])
--------------------------------------------------
  v: torch.Size([1, 70, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 70])
score dimension torch.Size([1, 8, 70, 70])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 13])
score dimension torch.Size([1, 8, 70, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 70, 512])
--------------------------------------------------
  v: torch.Size([1, 70, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 70])
score dimension torch.Size([1, 8, 70, 70])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 70, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 70, 13])
score dimension torch.Size([1, 8, 70, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 70, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 70, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 71])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 71
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 71])
  Token embedding: torch.Size([1, 71, 512])
  Position embedding: torch.Size([71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 71, 512])
--------------------------------------------------
  v: torch.Size([1, 71, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 71])
score dimension torch.Size([1, 8, 71, 71])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 13])
score dimension torch.Size([1, 8, 71, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 71, 512])
--------------------------------------------------
  v: torch.Size([1, 71, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 71])
score dimension torch.Size([1, 8, 71, 71])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 13])
score dimension torch.Size([1, 8, 71, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 71, 512])
--------------------------------------------------
  v: torch.Size([1, 71, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 71])
score dimension torch.Size([1, 8, 71, 71])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 13])
score dimension torch.Size([1, 8, 71, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 71, 512])
--------------------------------------------------
  v: torch.Size([1, 71, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 71])
score dimension torch.Size([1, 8, 71, 71])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 13])
score dimension torch.Size([1, 8, 71, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 71, 512])
--------------------------------------------------
  v: torch.Size([1, 71, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 71])
score dimension torch.Size([1, 8, 71, 71])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 13])
score dimension torch.Size([1, 8, 71, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 71, 512])
--------------------------------------------------
  v: torch.Size([1, 71, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 71])
score dimension torch.Size([1, 8, 71, 71])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 71, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 71, 13])
score dimension torch.Size([1, 8, 71, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 71, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 71, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 72])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 72
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 72])
  Token embedding: torch.Size([1, 72, 512])
  Position embedding: torch.Size([72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 72, 512])
--------------------------------------------------
  v: torch.Size([1, 72, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 72])
score dimension torch.Size([1, 8, 72, 72])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 13])
score dimension torch.Size([1, 8, 72, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 72, 512])
--------------------------------------------------
  v: torch.Size([1, 72, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 72])
score dimension torch.Size([1, 8, 72, 72])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 13])
score dimension torch.Size([1, 8, 72, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 72, 512])
--------------------------------------------------
  v: torch.Size([1, 72, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 72])
score dimension torch.Size([1, 8, 72, 72])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 13])
score dimension torch.Size([1, 8, 72, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 72, 512])
--------------------------------------------------
  v: torch.Size([1, 72, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 72])
score dimension torch.Size([1, 8, 72, 72])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 13])
score dimension torch.Size([1, 8, 72, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 72, 512])
--------------------------------------------------
  v: torch.Size([1, 72, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 72])
score dimension torch.Size([1, 8, 72, 72])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 13])
score dimension torch.Size([1, 8, 72, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 72, 512])
--------------------------------------------------
  v: torch.Size([1, 72, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 72])
score dimension torch.Size([1, 8, 72, 72])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 72, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 72, 13])
score dimension torch.Size([1, 8, 72, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 72, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 72, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 73])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 73
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 73])
  Token embedding: torch.Size([1, 73, 512])
  Position embedding: torch.Size([73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 73, 512])
--------------------------------------------------
  v: torch.Size([1, 73, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 73])
score dimension torch.Size([1, 8, 73, 73])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 13])
score dimension torch.Size([1, 8, 73, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 73, 512])
--------------------------------------------------
  v: torch.Size([1, 73, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 73])
score dimension torch.Size([1, 8, 73, 73])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 13])
score dimension torch.Size([1, 8, 73, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 73, 512])
--------------------------------------------------
  v: torch.Size([1, 73, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 73])
score dimension torch.Size([1, 8, 73, 73])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 13])
score dimension torch.Size([1, 8, 73, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 73, 512])
--------------------------------------------------
  v: torch.Size([1, 73, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 73])
score dimension torch.Size([1, 8, 73, 73])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 13])
score dimension torch.Size([1, 8, 73, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 73, 512])
--------------------------------------------------
  v: torch.Size([1, 73, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 73])
score dimension torch.Size([1, 8, 73, 73])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 13])
score dimension torch.Size([1, 8, 73, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 73, 512])
--------------------------------------------------
  v: torch.Size([1, 73, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 73])
score dimension torch.Size([1, 8, 73, 73])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 73, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 73, 13])
score dimension torch.Size([1, 8, 73, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 73, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 73, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 74])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 74
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 74])
  Token embedding: torch.Size([1, 74, 512])
  Position embedding: torch.Size([74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 74, 512])
--------------------------------------------------
  v: torch.Size([1, 74, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 74])
score dimension torch.Size([1, 8, 74, 74])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 13])
score dimension torch.Size([1, 8, 74, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 74, 512])
--------------------------------------------------
  v: torch.Size([1, 74, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 74])
score dimension torch.Size([1, 8, 74, 74])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 13])
score dimension torch.Size([1, 8, 74, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 74, 512])
--------------------------------------------------
  v: torch.Size([1, 74, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 74])
score dimension torch.Size([1, 8, 74, 74])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 13])
score dimension torch.Size([1, 8, 74, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 74, 512])
--------------------------------------------------
  v: torch.Size([1, 74, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 74])
score dimension torch.Size([1, 8, 74, 74])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 13])
score dimension torch.Size([1, 8, 74, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 74, 512])
--------------------------------------------------
  v: torch.Size([1, 74, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 74])
score dimension torch.Size([1, 8, 74, 74])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 13])
score dimension torch.Size([1, 8, 74, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 74, 512])
--------------------------------------------------
  v: torch.Size([1, 74, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 74])
score dimension torch.Size([1, 8, 74, 74])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 74, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 74, 13])
score dimension torch.Size([1, 8, 74, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 74, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 74, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 75])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 75
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 75])
  Token embedding: torch.Size([1, 75, 512])
  Position embedding: torch.Size([75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 75, 512])
--------------------------------------------------
  v: torch.Size([1, 75, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 75])
score dimension torch.Size([1, 8, 75, 75])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 13])
score dimension torch.Size([1, 8, 75, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 75, 512])
--------------------------------------------------
  v: torch.Size([1, 75, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 75])
score dimension torch.Size([1, 8, 75, 75])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 13])
score dimension torch.Size([1, 8, 75, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 75, 512])
--------------------------------------------------
  v: torch.Size([1, 75, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 75])
score dimension torch.Size([1, 8, 75, 75])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 13])
score dimension torch.Size([1, 8, 75, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 75, 512])
--------------------------------------------------
  v: torch.Size([1, 75, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 75])
score dimension torch.Size([1, 8, 75, 75])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 13])
score dimension torch.Size([1, 8, 75, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 75, 512])
--------------------------------------------------
  v: torch.Size([1, 75, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 75])
score dimension torch.Size([1, 8, 75, 75])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 13])
score dimension torch.Size([1, 8, 75, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 75, 512])
--------------------------------------------------
  v: torch.Size([1, 75, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 75])
score dimension torch.Size([1, 8, 75, 75])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 75, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 75, 13])
score dimension torch.Size([1, 8, 75, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 75, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 75, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 76])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 76
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 76])
  Token embedding: torch.Size([1, 76, 512])
  Position embedding: torch.Size([76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 76, 512])
--------------------------------------------------
  v: torch.Size([1, 76, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 76])
score dimension torch.Size([1, 8, 76, 76])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 13])
score dimension torch.Size([1, 8, 76, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 76, 512])
--------------------------------------------------
  v: torch.Size([1, 76, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 76])
score dimension torch.Size([1, 8, 76, 76])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 13])
score dimension torch.Size([1, 8, 76, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 76, 512])
--------------------------------------------------
  v: torch.Size([1, 76, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 76])
score dimension torch.Size([1, 8, 76, 76])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 13])
score dimension torch.Size([1, 8, 76, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 76, 512])
--------------------------------------------------
  v: torch.Size([1, 76, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 76])
score dimension torch.Size([1, 8, 76, 76])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 13])
score dimension torch.Size([1, 8, 76, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 76, 512])
--------------------------------------------------
  v: torch.Size([1, 76, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 76])
score dimension torch.Size([1, 8, 76, 76])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 13])
score dimension torch.Size([1, 8, 76, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 76, 512])
--------------------------------------------------
  v: torch.Size([1, 76, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 76])
score dimension torch.Size([1, 8, 76, 76])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 76, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 76, 13])
score dimension torch.Size([1, 8, 76, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 76, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 76, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 77])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 77
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 77])
  Token embedding: torch.Size([1, 77, 512])
  Position embedding: torch.Size([77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 77, 512])
--------------------------------------------------
  v: torch.Size([1, 77, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 77])
score dimension torch.Size([1, 8, 77, 77])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 13])
score dimension torch.Size([1, 8, 77, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 77, 512])
--------------------------------------------------
  v: torch.Size([1, 77, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 77])
score dimension torch.Size([1, 8, 77, 77])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 13])
score dimension torch.Size([1, 8, 77, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 77, 512])
--------------------------------------------------
  v: torch.Size([1, 77, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 77])
score dimension torch.Size([1, 8, 77, 77])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 13])
score dimension torch.Size([1, 8, 77, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 77, 512])
--------------------------------------------------
  v: torch.Size([1, 77, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 77])
score dimension torch.Size([1, 8, 77, 77])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 13])
score dimension torch.Size([1, 8, 77, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 77, 512])
--------------------------------------------------
  v: torch.Size([1, 77, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 77])
score dimension torch.Size([1, 8, 77, 77])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 13])
score dimension torch.Size([1, 8, 77, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 77, 512])
--------------------------------------------------
  v: torch.Size([1, 77, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 77])
score dimension torch.Size([1, 8, 77, 77])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 77, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 77, 13])
score dimension torch.Size([1, 8, 77, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 77, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 77, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 78])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 78
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 78])
  Token embedding: torch.Size([1, 78, 512])
  Position embedding: torch.Size([78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 78, 512])
--------------------------------------------------
  v: torch.Size([1, 78, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 78])
score dimension torch.Size([1, 8, 78, 78])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 13])
score dimension torch.Size([1, 8, 78, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 78, 512])
--------------------------------------------------
  v: torch.Size([1, 78, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 78])
score dimension torch.Size([1, 8, 78, 78])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 13])
score dimension torch.Size([1, 8, 78, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 78, 512])
--------------------------------------------------
  v: torch.Size([1, 78, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 78])
score dimension torch.Size([1, 8, 78, 78])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 13])
score dimension torch.Size([1, 8, 78, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 78, 512])
--------------------------------------------------
  v: torch.Size([1, 78, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 78])
score dimension torch.Size([1, 8, 78, 78])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 13])
score dimension torch.Size([1, 8, 78, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 78, 512])
--------------------------------------------------
  v: torch.Size([1, 78, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 78])
score dimension torch.Size([1, 8, 78, 78])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 13])
score dimension torch.Size([1, 8, 78, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 78, 512])
--------------------------------------------------
  v: torch.Size([1, 78, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 78])
score dimension torch.Size([1, 8, 78, 78])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 78, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 78, 13])
score dimension torch.Size([1, 8, 78, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 78, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 78, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 79])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 79
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 79])
  Token embedding: torch.Size([1, 79, 512])
  Position embedding: torch.Size([79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 79, 512])
--------------------------------------------------
  v: torch.Size([1, 79, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 79])
score dimension torch.Size([1, 8, 79, 79])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 13])
score dimension torch.Size([1, 8, 79, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 79, 512])
--------------------------------------------------
  v: torch.Size([1, 79, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 79])
score dimension torch.Size([1, 8, 79, 79])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 13])
score dimension torch.Size([1, 8, 79, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 79, 512])
--------------------------------------------------
  v: torch.Size([1, 79, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 79])
score dimension torch.Size([1, 8, 79, 79])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 13])
score dimension torch.Size([1, 8, 79, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 79, 512])
--------------------------------------------------
  v: torch.Size([1, 79, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 79])
score dimension torch.Size([1, 8, 79, 79])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 13])
score dimension torch.Size([1, 8, 79, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 79, 512])
--------------------------------------------------
  v: torch.Size([1, 79, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 79])
score dimension torch.Size([1, 8, 79, 79])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 13])
score dimension torch.Size([1, 8, 79, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 79, 512])
--------------------------------------------------
  v: torch.Size([1, 79, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 79])
score dimension torch.Size([1, 8, 79, 79])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 79, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 79, 13])
score dimension torch.Size([1, 8, 79, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 79, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 79, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 80])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 80
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 80])
  Token embedding: torch.Size([1, 80, 512])
  Position embedding: torch.Size([80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 80, 512])
--------------------------------------------------
  v: torch.Size([1, 80, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 80])
score dimension torch.Size([1, 8, 80, 80])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 13])
score dimension torch.Size([1, 8, 80, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 80, 512])
--------------------------------------------------
  v: torch.Size([1, 80, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 80])
score dimension torch.Size([1, 8, 80, 80])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 13])
score dimension torch.Size([1, 8, 80, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 80, 512])
--------------------------------------------------
  v: torch.Size([1, 80, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 80])
score dimension torch.Size([1, 8, 80, 80])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 13])
score dimension torch.Size([1, 8, 80, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 80, 512])
--------------------------------------------------
  v: torch.Size([1, 80, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 80])
score dimension torch.Size([1, 8, 80, 80])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 13])
score dimension torch.Size([1, 8, 80, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 80, 512])
--------------------------------------------------
  v: torch.Size([1, 80, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 80])
score dimension torch.Size([1, 8, 80, 80])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 13])
score dimension torch.Size([1, 8, 80, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 80, 512])
--------------------------------------------------
  v: torch.Size([1, 80, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 80])
score dimension torch.Size([1, 8, 80, 80])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 80, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 80, 13])
score dimension torch.Size([1, 8, 80, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 80, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 80, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 81])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 81
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 81])
  Token embedding: torch.Size([1, 81, 512])
  Position embedding: torch.Size([81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 81, 512])
--------------------------------------------------
  v: torch.Size([1, 81, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 81])
score dimension torch.Size([1, 8, 81, 81])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 13])
score dimension torch.Size([1, 8, 81, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 81, 512])
--------------------------------------------------
  v: torch.Size([1, 81, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 81])
score dimension torch.Size([1, 8, 81, 81])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 13])
score dimension torch.Size([1, 8, 81, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 81, 512])
--------------------------------------------------
  v: torch.Size([1, 81, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 81])
score dimension torch.Size([1, 8, 81, 81])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 13])
score dimension torch.Size([1, 8, 81, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 81, 512])
--------------------------------------------------
  v: torch.Size([1, 81, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 81])
score dimension torch.Size([1, 8, 81, 81])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 13])
score dimension torch.Size([1, 8, 81, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 81, 512])
--------------------------------------------------
  v: torch.Size([1, 81, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 81])
score dimension torch.Size([1, 8, 81, 81])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 13])
score dimension torch.Size([1, 8, 81, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 81, 512])
--------------------------------------------------
  v: torch.Size([1, 81, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 81])
score dimension torch.Size([1, 8, 81, 81])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 81, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 81, 13])
score dimension torch.Size([1, 8, 81, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 81, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 81, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 82])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 82
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 82])
  Token embedding: torch.Size([1, 82, 512])
  Position embedding: torch.Size([82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 82, 512])
--------------------------------------------------
  v: torch.Size([1, 82, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 82])
score dimension torch.Size([1, 8, 82, 82])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 13])
score dimension torch.Size([1, 8, 82, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 82, 512])
--------------------------------------------------
  v: torch.Size([1, 82, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 82])
score dimension torch.Size([1, 8, 82, 82])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 13])
score dimension torch.Size([1, 8, 82, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 82, 512])
--------------------------------------------------
  v: torch.Size([1, 82, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 82])
score dimension torch.Size([1, 8, 82, 82])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 13])
score dimension torch.Size([1, 8, 82, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 82, 512])
--------------------------------------------------
  v: torch.Size([1, 82, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 82])
score dimension torch.Size([1, 8, 82, 82])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 13])
score dimension torch.Size([1, 8, 82, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 82, 512])
--------------------------------------------------
  v: torch.Size([1, 82, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 82])
score dimension torch.Size([1, 8, 82, 82])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 13])
score dimension torch.Size([1, 8, 82, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 82, 512])
--------------------------------------------------
  v: torch.Size([1, 82, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 82])
score dimension torch.Size([1, 8, 82, 82])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 82, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 82, 13])
score dimension torch.Size([1, 8, 82, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 82, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 82, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 83])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 83
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 83])
  Token embedding: torch.Size([1, 83, 512])
  Position embedding: torch.Size([83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 83, 512])
--------------------------------------------------
  v: torch.Size([1, 83, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 83])
score dimension torch.Size([1, 8, 83, 83])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 13])
score dimension torch.Size([1, 8, 83, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 83, 512])
--------------------------------------------------
  v: torch.Size([1, 83, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 83])
score dimension torch.Size([1, 8, 83, 83])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 13])
score dimension torch.Size([1, 8, 83, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 83, 512])
--------------------------------------------------
  v: torch.Size([1, 83, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 83])
score dimension torch.Size([1, 8, 83, 83])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 13])
score dimension torch.Size([1, 8, 83, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 83, 512])
--------------------------------------------------
  v: torch.Size([1, 83, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 83])
score dimension torch.Size([1, 8, 83, 83])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 13])
score dimension torch.Size([1, 8, 83, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 83, 512])
--------------------------------------------------
  v: torch.Size([1, 83, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 83])
score dimension torch.Size([1, 8, 83, 83])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 13])
score dimension torch.Size([1, 8, 83, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 83, 512])
--------------------------------------------------
  v: torch.Size([1, 83, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 83])
score dimension torch.Size([1, 8, 83, 83])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 83, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 83, 13])
score dimension torch.Size([1, 8, 83, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 83, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 83, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 84])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 84
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 84])
  Token embedding: torch.Size([1, 84, 512])
  Position embedding: torch.Size([84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 84, 512])
--------------------------------------------------
  v: torch.Size([1, 84, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 84])
score dimension torch.Size([1, 8, 84, 84])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 13])
score dimension torch.Size([1, 8, 84, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 84, 512])
--------------------------------------------------
  v: torch.Size([1, 84, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 84])
score dimension torch.Size([1, 8, 84, 84])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 13])
score dimension torch.Size([1, 8, 84, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 84, 512])
--------------------------------------------------
  v: torch.Size([1, 84, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 84])
score dimension torch.Size([1, 8, 84, 84])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 13])
score dimension torch.Size([1, 8, 84, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 84, 512])
--------------------------------------------------
  v: torch.Size([1, 84, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 84])
score dimension torch.Size([1, 8, 84, 84])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 13])
score dimension torch.Size([1, 8, 84, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 84, 512])
--------------------------------------------------
  v: torch.Size([1, 84, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 84])
score dimension torch.Size([1, 8, 84, 84])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 13])
score dimension torch.Size([1, 8, 84, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 84, 512])
--------------------------------------------------
  v: torch.Size([1, 84, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 84])
score dimension torch.Size([1, 8, 84, 84])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 84, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 84, 13])
score dimension torch.Size([1, 8, 84, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 84, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 84, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 85])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 85
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 85])
  Token embedding: torch.Size([1, 85, 512])
  Position embedding: torch.Size([85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 85, 512])
--------------------------------------------------
  v: torch.Size([1, 85, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 85])
score dimension torch.Size([1, 8, 85, 85])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 13])
score dimension torch.Size([1, 8, 85, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 85, 512])
--------------------------------------------------
  v: torch.Size([1, 85, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 85])
score dimension torch.Size([1, 8, 85, 85])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 13])
score dimension torch.Size([1, 8, 85, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 85, 512])
--------------------------------------------------
  v: torch.Size([1, 85, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 85])
score dimension torch.Size([1, 8, 85, 85])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 13])
score dimension torch.Size([1, 8, 85, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 85, 512])
--------------------------------------------------
  v: torch.Size([1, 85, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 85])
score dimension torch.Size([1, 8, 85, 85])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 13])
score dimension torch.Size([1, 8, 85, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 85, 512])
--------------------------------------------------
  v: torch.Size([1, 85, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 85])
score dimension torch.Size([1, 8, 85, 85])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 13])
score dimension torch.Size([1, 8, 85, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 85, 512])
--------------------------------------------------
  v: torch.Size([1, 85, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 85])
score dimension torch.Size([1, 8, 85, 85])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 85, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 85, 13])
score dimension torch.Size([1, 8, 85, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 85, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 85, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 86])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 86
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 86])
  Token embedding: torch.Size([1, 86, 512])
  Position embedding: torch.Size([86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 86, 512])
--------------------------------------------------
  v: torch.Size([1, 86, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 86])
score dimension torch.Size([1, 8, 86, 86])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 13])
score dimension torch.Size([1, 8, 86, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 86, 512])
--------------------------------------------------
  v: torch.Size([1, 86, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 86])
score dimension torch.Size([1, 8, 86, 86])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 13])
score dimension torch.Size([1, 8, 86, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 86, 512])
--------------------------------------------------
  v: torch.Size([1, 86, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 86])
score dimension torch.Size([1, 8, 86, 86])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 13])
score dimension torch.Size([1, 8, 86, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 86, 512])
--------------------------------------------------
  v: torch.Size([1, 86, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 86])
score dimension torch.Size([1, 8, 86, 86])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 13])
score dimension torch.Size([1, 8, 86, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 86, 512])
--------------------------------------------------
  v: torch.Size([1, 86, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 86])
score dimension torch.Size([1, 8, 86, 86])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 13])
score dimension torch.Size([1, 8, 86, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 86, 512])
--------------------------------------------------
  v: torch.Size([1, 86, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 86])
score dimension torch.Size([1, 8, 86, 86])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 86, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 86, 13])
score dimension torch.Size([1, 8, 86, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 86, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 86, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 87])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 87
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 87])
  Token embedding: torch.Size([1, 87, 512])
  Position embedding: torch.Size([87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 87, 512])
--------------------------------------------------
  v: torch.Size([1, 87, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 87])
score dimension torch.Size([1, 8, 87, 87])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 13])
score dimension torch.Size([1, 8, 87, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 87, 512])
--------------------------------------------------
  v: torch.Size([1, 87, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 87])
score dimension torch.Size([1, 8, 87, 87])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 13])
score dimension torch.Size([1, 8, 87, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 87, 512])
--------------------------------------------------
  v: torch.Size([1, 87, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 87])
score dimension torch.Size([1, 8, 87, 87])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 13])
score dimension torch.Size([1, 8, 87, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 87, 512])
--------------------------------------------------
  v: torch.Size([1, 87, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 87])
score dimension torch.Size([1, 8, 87, 87])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 13])
score dimension torch.Size([1, 8, 87, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 87, 512])
--------------------------------------------------
  v: torch.Size([1, 87, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 87])
score dimension torch.Size([1, 8, 87, 87])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 13])
score dimension torch.Size([1, 8, 87, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 87, 512])
--------------------------------------------------
  v: torch.Size([1, 87, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 87])
score dimension torch.Size([1, 8, 87, 87])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 87, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 87, 13])
score dimension torch.Size([1, 8, 87, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 87, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 87, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 88])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 88
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 88])
  Token embedding: torch.Size([1, 88, 512])
  Position embedding: torch.Size([88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 88, 512])
--------------------------------------------------
  v: torch.Size([1, 88, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 88])
score dimension torch.Size([1, 8, 88, 88])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 13])
score dimension torch.Size([1, 8, 88, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 88, 512])
--------------------------------------------------
  v: torch.Size([1, 88, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 88])
score dimension torch.Size([1, 8, 88, 88])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 13])
score dimension torch.Size([1, 8, 88, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 88, 512])
--------------------------------------------------
  v: torch.Size([1, 88, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 88])
score dimension torch.Size([1, 8, 88, 88])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 13])
score dimension torch.Size([1, 8, 88, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 88, 512])
--------------------------------------------------
  v: torch.Size([1, 88, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 88])
score dimension torch.Size([1, 8, 88, 88])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 13])
score dimension torch.Size([1, 8, 88, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 88, 512])
--------------------------------------------------
  v: torch.Size([1, 88, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 88])
score dimension torch.Size([1, 8, 88, 88])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 13])
score dimension torch.Size([1, 8, 88, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 88, 512])
--------------------------------------------------
  v: torch.Size([1, 88, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 88])
score dimension torch.Size([1, 8, 88, 88])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 88, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 88, 13])
score dimension torch.Size([1, 8, 88, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 88, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 88, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 89])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 89
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 89])
  Token embedding: torch.Size([1, 89, 512])
  Position embedding: torch.Size([89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 89, 512])
--------------------------------------------------
  v: torch.Size([1, 89, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 89])
score dimension torch.Size([1, 8, 89, 89])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 13])
score dimension torch.Size([1, 8, 89, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 89, 512])
--------------------------------------------------
  v: torch.Size([1, 89, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 89])
score dimension torch.Size([1, 8, 89, 89])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 13])
score dimension torch.Size([1, 8, 89, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 89, 512])
--------------------------------------------------
  v: torch.Size([1, 89, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 89])
score dimension torch.Size([1, 8, 89, 89])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 13])
score dimension torch.Size([1, 8, 89, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 89, 512])
--------------------------------------------------
  v: torch.Size([1, 89, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 89])
score dimension torch.Size([1, 8, 89, 89])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 13])
score dimension torch.Size([1, 8, 89, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 89, 512])
--------------------------------------------------
  v: torch.Size([1, 89, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 89])
score dimension torch.Size([1, 8, 89, 89])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 13])
score dimension torch.Size([1, 8, 89, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 89, 512])
--------------------------------------------------
  v: torch.Size([1, 89, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 89])
score dimension torch.Size([1, 8, 89, 89])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 89, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 89, 13])
score dimension torch.Size([1, 8, 89, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 89, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 89, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 90])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 90
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 90])
  Token embedding: torch.Size([1, 90, 512])
  Position embedding: torch.Size([90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 90, 512])
--------------------------------------------------
  v: torch.Size([1, 90, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 90])
score dimension torch.Size([1, 8, 90, 90])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 13])
score dimension torch.Size([1, 8, 90, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 90, 512])
--------------------------------------------------
  v: torch.Size([1, 90, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 90])
score dimension torch.Size([1, 8, 90, 90])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 13])
score dimension torch.Size([1, 8, 90, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 90, 512])
--------------------------------------------------
  v: torch.Size([1, 90, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 90])
score dimension torch.Size([1, 8, 90, 90])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 13])
score dimension torch.Size([1, 8, 90, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 90, 512])
--------------------------------------------------
  v: torch.Size([1, 90, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 90])
score dimension torch.Size([1, 8, 90, 90])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 13])
score dimension torch.Size([1, 8, 90, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 90, 512])
--------------------------------------------------
  v: torch.Size([1, 90, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 90])
score dimension torch.Size([1, 8, 90, 90])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 13])
score dimension torch.Size([1, 8, 90, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 90, 512])
--------------------------------------------------
  v: torch.Size([1, 90, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 90])
score dimension torch.Size([1, 8, 90, 90])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 90, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 90, 13])
score dimension torch.Size([1, 8, 90, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 90, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 90, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 91])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 91
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 91])
  Token embedding: torch.Size([1, 91, 512])
  Position embedding: torch.Size([91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 91, 512])
--------------------------------------------------
  v: torch.Size([1, 91, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 91])
score dimension torch.Size([1, 8, 91, 91])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 13])
score dimension torch.Size([1, 8, 91, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 91, 512])
--------------------------------------------------
  v: torch.Size([1, 91, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 91])
score dimension torch.Size([1, 8, 91, 91])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 13])
score dimension torch.Size([1, 8, 91, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 91, 512])
--------------------------------------------------
  v: torch.Size([1, 91, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 91])
score dimension torch.Size([1, 8, 91, 91])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 13])
score dimension torch.Size([1, 8, 91, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 91, 512])
--------------------------------------------------
  v: torch.Size([1, 91, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 91])
score dimension torch.Size([1, 8, 91, 91])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 13])
score dimension torch.Size([1, 8, 91, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 91, 512])
--------------------------------------------------
  v: torch.Size([1, 91, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 91])
score dimension torch.Size([1, 8, 91, 91])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 13])
score dimension torch.Size([1, 8, 91, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 91, 512])
--------------------------------------------------
  v: torch.Size([1, 91, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 91])
score dimension torch.Size([1, 8, 91, 91])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 91, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 91, 13])
score dimension torch.Size([1, 8, 91, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 91, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 91, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 92])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 92
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 92])
  Token embedding: torch.Size([1, 92, 512])
  Position embedding: torch.Size([92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 92, 512])
--------------------------------------------------
  v: torch.Size([1, 92, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 92])
score dimension torch.Size([1, 8, 92, 92])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 13])
score dimension torch.Size([1, 8, 92, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 92, 512])
--------------------------------------------------
  v: torch.Size([1, 92, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 92])
score dimension torch.Size([1, 8, 92, 92])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 13])
score dimension torch.Size([1, 8, 92, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 92, 512])
--------------------------------------------------
  v: torch.Size([1, 92, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 92])
score dimension torch.Size([1, 8, 92, 92])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 13])
score dimension torch.Size([1, 8, 92, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 92, 512])
--------------------------------------------------
  v: torch.Size([1, 92, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 92])
score dimension torch.Size([1, 8, 92, 92])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 13])
score dimension torch.Size([1, 8, 92, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 92, 512])
--------------------------------------------------
  v: torch.Size([1, 92, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 92])
score dimension torch.Size([1, 8, 92, 92])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 13])
score dimension torch.Size([1, 8, 92, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 92, 512])
--------------------------------------------------
  v: torch.Size([1, 92, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 92])
score dimension torch.Size([1, 8, 92, 92])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 92, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 92, 13])
score dimension torch.Size([1, 8, 92, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 92, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 92, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 93])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 93
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 93])
  Token embedding: torch.Size([1, 93, 512])
  Position embedding: torch.Size([93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 93, 512])
--------------------------------------------------
  v: torch.Size([1, 93, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 93])
score dimension torch.Size([1, 8, 93, 93])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 13])
score dimension torch.Size([1, 8, 93, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 93, 512])
--------------------------------------------------
  v: torch.Size([1, 93, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 93])
score dimension torch.Size([1, 8, 93, 93])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 13])
score dimension torch.Size([1, 8, 93, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 93, 512])
--------------------------------------------------
  v: torch.Size([1, 93, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 93])
score dimension torch.Size([1, 8, 93, 93])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 13])
score dimension torch.Size([1, 8, 93, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 93, 512])
--------------------------------------------------
  v: torch.Size([1, 93, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 93])
score dimension torch.Size([1, 8, 93, 93])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 13])
score dimension torch.Size([1, 8, 93, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 93, 512])
--------------------------------------------------
  v: torch.Size([1, 93, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 93])
score dimension torch.Size([1, 8, 93, 93])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 13])
score dimension torch.Size([1, 8, 93, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 93, 512])
--------------------------------------------------
  v: torch.Size([1, 93, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 93])
score dimension torch.Size([1, 8, 93, 93])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 93, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 93, 13])
score dimension torch.Size([1, 8, 93, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 93, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 93, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 94])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 94
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 94])
  Token embedding: torch.Size([1, 94, 512])
  Position embedding: torch.Size([94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 94, 512])
--------------------------------------------------
  v: torch.Size([1, 94, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 94])
score dimension torch.Size([1, 8, 94, 94])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 13])
score dimension torch.Size([1, 8, 94, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 94, 512])
--------------------------------------------------
  v: torch.Size([1, 94, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 94])
score dimension torch.Size([1, 8, 94, 94])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 13])
score dimension torch.Size([1, 8, 94, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 94, 512])
--------------------------------------------------
  v: torch.Size([1, 94, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 94])
score dimension torch.Size([1, 8, 94, 94])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 13])
score dimension torch.Size([1, 8, 94, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 94, 512])
--------------------------------------------------
  v: torch.Size([1, 94, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 94])
score dimension torch.Size([1, 8, 94, 94])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 13])
score dimension torch.Size([1, 8, 94, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 94, 512])
--------------------------------------------------
  v: torch.Size([1, 94, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 94])
score dimension torch.Size([1, 8, 94, 94])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 13])
score dimension torch.Size([1, 8, 94, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 94, 512])
--------------------------------------------------
  v: torch.Size([1, 94, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 94])
score dimension torch.Size([1, 8, 94, 94])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 94, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 94, 13])
score dimension torch.Size([1, 8, 94, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 94, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 94, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 95])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 95
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 95])
  Token embedding: torch.Size([1, 95, 512])
  Position embedding: torch.Size([95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 95, 512])
--------------------------------------------------
  v: torch.Size([1, 95, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 95])
score dimension torch.Size([1, 8, 95, 95])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 13])
score dimension torch.Size([1, 8, 95, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 95, 512])
--------------------------------------------------
  v: torch.Size([1, 95, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 95])
score dimension torch.Size([1, 8, 95, 95])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 13])
score dimension torch.Size([1, 8, 95, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 95, 512])
--------------------------------------------------
  v: torch.Size([1, 95, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 95])
score dimension torch.Size([1, 8, 95, 95])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 13])
score dimension torch.Size([1, 8, 95, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 95, 512])
--------------------------------------------------
  v: torch.Size([1, 95, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 95])
score dimension torch.Size([1, 8, 95, 95])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 13])
score dimension torch.Size([1, 8, 95, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 95, 512])
--------------------------------------------------
  v: torch.Size([1, 95, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 95])
score dimension torch.Size([1, 8, 95, 95])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 13])
score dimension torch.Size([1, 8, 95, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 95, 512])
--------------------------------------------------
  v: torch.Size([1, 95, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 95])
score dimension torch.Size([1, 8, 95, 95])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 95, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 95, 13])
score dimension torch.Size([1, 8, 95, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 95, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 95, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 96])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 96
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 96])
  Token embedding: torch.Size([1, 96, 512])
  Position embedding: torch.Size([96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 96, 512])
--------------------------------------------------
  v: torch.Size([1, 96, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 96])
score dimension torch.Size([1, 8, 96, 96])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 13])
score dimension torch.Size([1, 8, 96, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 96, 512])
--------------------------------------------------
  v: torch.Size([1, 96, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 96])
score dimension torch.Size([1, 8, 96, 96])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 13])
score dimension torch.Size([1, 8, 96, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 96, 512])
--------------------------------------------------
  v: torch.Size([1, 96, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 96])
score dimension torch.Size([1, 8, 96, 96])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 13])
score dimension torch.Size([1, 8, 96, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 96, 512])
--------------------------------------------------
  v: torch.Size([1, 96, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 96])
score dimension torch.Size([1, 8, 96, 96])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 13])
score dimension torch.Size([1, 8, 96, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 96, 512])
--------------------------------------------------
  v: torch.Size([1, 96, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 96])
score dimension torch.Size([1, 8, 96, 96])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 13])
score dimension torch.Size([1, 8, 96, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 96, 512])
--------------------------------------------------
  v: torch.Size([1, 96, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 96])
score dimension torch.Size([1, 8, 96, 96])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 96, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 96, 13])
score dimension torch.Size([1, 8, 96, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 96, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 96, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 97])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 97
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 97])
  Token embedding: torch.Size([1, 97, 512])
  Position embedding: torch.Size([97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 97, 512])
--------------------------------------------------
  v: torch.Size([1, 97, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 97])
score dimension torch.Size([1, 8, 97, 97])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 13])
score dimension torch.Size([1, 8, 97, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 97, 512])
--------------------------------------------------
  v: torch.Size([1, 97, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 97])
score dimension torch.Size([1, 8, 97, 97])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 13])
score dimension torch.Size([1, 8, 97, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 97, 512])
--------------------------------------------------
  v: torch.Size([1, 97, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 97])
score dimension torch.Size([1, 8, 97, 97])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 13])
score dimension torch.Size([1, 8, 97, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 97, 512])
--------------------------------------------------
  v: torch.Size([1, 97, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 97])
score dimension torch.Size([1, 8, 97, 97])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 13])
score dimension torch.Size([1, 8, 97, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 97, 512])
--------------------------------------------------
  v: torch.Size([1, 97, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 97])
score dimension torch.Size([1, 8, 97, 97])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 13])
score dimension torch.Size([1, 8, 97, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 97, 512])
--------------------------------------------------
  v: torch.Size([1, 97, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 97])
score dimension torch.Size([1, 8, 97, 97])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 97, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 97, 13])
score dimension torch.Size([1, 8, 97, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 97, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 97, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 98])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 98
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 98])
  Token embedding: torch.Size([1, 98, 512])
  Position embedding: torch.Size([98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 98, 512])
--------------------------------------------------
  v: torch.Size([1, 98, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 98])
score dimension torch.Size([1, 8, 98, 98])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 13])
score dimension torch.Size([1, 8, 98, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 98, 512])
--------------------------------------------------
  v: torch.Size([1, 98, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 98])
score dimension torch.Size([1, 8, 98, 98])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 13])
score dimension torch.Size([1, 8, 98, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 98, 512])
--------------------------------------------------
  v: torch.Size([1, 98, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 98])
score dimension torch.Size([1, 8, 98, 98])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 13])
score dimension torch.Size([1, 8, 98, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 98, 512])
--------------------------------------------------
  v: torch.Size([1, 98, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 98])
score dimension torch.Size([1, 8, 98, 98])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 13])
score dimension torch.Size([1, 8, 98, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 98, 512])
--------------------------------------------------
  v: torch.Size([1, 98, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 98])
score dimension torch.Size([1, 8, 98, 98])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 13])
score dimension torch.Size([1, 8, 98, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 98, 512])
--------------------------------------------------
  v: torch.Size([1, 98, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 98])
score dimension torch.Size([1, 8, 98, 98])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 98, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 98, 13])
score dimension torch.Size([1, 8, 98, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 98, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 98, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 99])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 99
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 99])
  Token embedding: torch.Size([1, 99, 512])
  Position embedding: torch.Size([99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 99, 512])
--------------------------------------------------
  v: torch.Size([1, 99, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 99])
score dimension torch.Size([1, 8, 99, 99])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 13])
score dimension torch.Size([1, 8, 99, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 99, 512])
--------------------------------------------------
  v: torch.Size([1, 99, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 99])
score dimension torch.Size([1, 8, 99, 99])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 13])
score dimension torch.Size([1, 8, 99, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 99, 512])
--------------------------------------------------
  v: torch.Size([1, 99, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 99])
score dimension torch.Size([1, 8, 99, 99])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 13])
score dimension torch.Size([1, 8, 99, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 99, 512])
--------------------------------------------------
  v: torch.Size([1, 99, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 99])
score dimension torch.Size([1, 8, 99, 99])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 13])
score dimension torch.Size([1, 8, 99, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 99, 512])
--------------------------------------------------
  v: torch.Size([1, 99, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 99])
score dimension torch.Size([1, 8, 99, 99])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 13])
score dimension torch.Size([1, 8, 99, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 99, 512])
--------------------------------------------------
  v: torch.Size([1, 99, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 99])
score dimension torch.Size([1, 8, 99, 99])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 99, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 99, 13])
score dimension torch.Size([1, 8, 99, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 99, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 99, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 13
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 13])
  Token embedding: torch.Size([1, 13, 512])
  Position embedding: torch.Size([13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 13, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 13, 13])
score dimension torch.Size([1, 8, 13, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 13, 512])
==================================================
==================================================
[DEBUG] PositionalEmbedding dimensions:
  Input x: torch.Size([1, 100])
  Encoding shape: torch.Size([100, 512])
  Sequence length: 100
==================================================
==================================================
[DEBUG] TransformerEmbedding dimensions:
  Input x: torch.Size([1, 100])
  Token embedding: torch.Size([1, 100, 512])
  Position embedding: torch.Size([100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 100, 512])
--------------------------------------------------
  v: torch.Size([1, 100, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 100])
score dimension torch.Size([1, 8, 100, 100])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 13])
score dimension torch.Size([1, 8, 100, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 100, 512])
--------------------------------------------------
  v: torch.Size([1, 100, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 100])
score dimension torch.Size([1, 8, 100, 100])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 13])
score dimension torch.Size([1, 8, 100, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 100, 512])
--------------------------------------------------
  v: torch.Size([1, 100, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 100])
score dimension torch.Size([1, 8, 100, 100])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 13])
score dimension torch.Size([1, 8, 100, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 100, 512])
--------------------------------------------------
  v: torch.Size([1, 100, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 100])
score dimension torch.Size([1, 8, 100, 100])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 13])
score dimension torch.Size([1, 8, 100, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 100, 512])
--------------------------------------------------
  v: torch.Size([1, 100, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 100])
score dimension torch.Size([1, 8, 100, 100])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 13])
score dimension torch.Size([1, 8, 100, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 100, 512])
--------------------------------------------------
  v: torch.Size([1, 100, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 100])
score dimension torch.Size([1, 8, 100, 100])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
==================================================
[DEBUG] Input dimensions:
==================================================
  q: torch.Size([1, 100, 512])
--------------------------------------------------
  k: torch.Size([1, 13, 512])
--------------------------------------------------
  v: torch.Size([1, 13, 512])
--------------------------------------------------
  batch_size: 1
==================================================
mask dimension torch.Size([1, 1, 100, 13])
score dimension torch.Size([1, 8, 100, 13])
==================================================
[DEBUG] MultiHeadAttention shapes:
==================================================
  q: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  k: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  v: torch.Size([1, 8, 13, 64])
--------------------------------------------------
  score: torch.Size([1, 8, 100, 64])
--------------------------------------------------
  d_model: 512, n_head: 8
--------------------------------------------------
  n_d (d_model/n_head): 64
==================================================
  final score: torch.Size([1, 100, 512])
==================================================
ĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMamĠMam
